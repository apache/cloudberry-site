"use strict";(self.webpackChunkApache_Cloudberry_Incubating_website=self.webpackChunkApache_Cloudberry_Incubating_website||[]).push([[82170],{95191:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>d});var s=t(85893),i=t(11151);const r={title:"Test and Debug Text Search"},a="Test and Debug Text Search",o={id:"operate-with-data/sql-queries/full-text-search/test-and-debug-text-search",title:"Test and Debug Text Search",description:"This document introduces the Apache Cloudberry functions you can use to test and debug a search configuration or the individual parser and dictionaries specified in a configuration.",source:"@site/versioned_docs/version-2.x/operate-with-data/sql-queries/full-text-search/test-and-debug-text-search.md",sourceDirName:"operate-with-data/sql-queries/full-text-search",slug:"/operate-with-data/sql-queries/full-text-search/test-and-debug-text-search",permalink:"/docs/operate-with-data/sql-queries/full-text-search/test-and-debug-text-search",draft:!1,unlisted:!1,editUrl:"https://github.com/apache/cloudberry-site/edit/main/versioned_docs/version-2.x/operate-with-data/sql-queries/full-text-search/test-and-debug-text-search.md",tags:[],version:"2.x",lastUpdatedBy:"TomShawn",lastUpdatedAt:1749026520,formattedLastUpdatedAt:"Jun 4, 2025",frontMatter:{title:"Test and Debug Text Search"},sidebar:"docsbars",previous:{title:"Text Search Configuration Example",permalink:"/docs/operate-with-data/sql-queries/full-text-search/text-search-configuration"},next:{title:"Preferred Index Types for Text Search",permalink:"/docs/operate-with-data/sql-queries/full-text-search/preferred-indexes-for-full-text-search"}},l={},d=[{value:"Configuration testing",id:"configuration-testing",level:2},{value:"Parser testing",id:"parser-testing",level:2},{value:"Dictionary testing",id:"dictionary-testing",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"test-and-debug-text-search",children:"Test and Debug Text Search"}),"\n",(0,s.jsx)(n.p,{children:"This document introduces the Apache Cloudberry functions you can use to test and debug a search configuration or the individual parser and dictionaries specified in a configuration."}),"\n",(0,s.jsx)(n.p,{children:"The behavior of a custom text search configuration can easily become confusing. The functions described in this section are useful for testing text search objects. You can test a complete configuration, or test parsers and dictionaries separately."}),"\n",(0,s.jsx)(n.p,{children:"This section contains the following subtopics:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#configuration-testing",children:"Configuration testing"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#parser-testing",children:"Parser testing"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#dictionary-testing",children:"Dictionary testing"})}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"configuration-testing",children:"Configuration testing"}),"\n",(0,s.jsxs)(n.p,{children:["The function ",(0,s.jsx)(n.code,{children:"ts_debug"})," allows easy testing of a text search configuration."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"ts_debug([<config> regconfig, ] <document> text,\n         OUT <alias> text,\n         OUT <description> text,\n         OUT <token> text,\n         OUT <dictionaries> regdictionary[],\n         OUT <dictionary> regdictionary,\n         OUT <lexemes> text[])\n         returns setof record\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"ts_debug"})," displays information about every token of ",(0,s.jsx)(n.code,{children:"*document*"})," as produced by the parser and processed by the configured dictionaries. It uses the configuration specified by ",(0,s.jsx)(n.code,{children:"*config*"}),", or ",(0,s.jsx)(n.code,{children:"default_text_search_config"})," if that argument is omitted."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"ts_debug"})," returns one row for each token identified in the text by the parser. The columns returned are"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"*alias* text"})," \u2014 short name of the token type"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"*description* text"})," \u2014 description of the token type"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"*token* text"}),"\u2014 text of the token"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"*dictionaries* regdictionary[]"})," \u2014 the dictionaries selected by the configuration for this token type"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"*dictionary* regdictionary"})," \u2014 the dictionary that recognized the token, or ",(0,s.jsx)(n.code,{children:"NULL"})," if none did"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"*lexemes* text[]"})," \u2014 the lexeme(s) produced by the dictionary that recognized the token, or ",(0,s.jsx)(n.code,{children:"NULL"})," if none did; an empty array (",(0,s.jsx)(n.code,{children:"{}"}),") means it was recognized as a stop word"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Here is a simple example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM ts_debug('english', 'a fat  cat sat on a mat - it ate a fat rats');\n   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes \n-----------+-----------------+-------+----------------+--------------+---------\n asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | cat   | {english_stem} | english_stem | {cat}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | sat   | {english_stem} | english_stem | {sat}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | on    | {english_stem} | english_stem | {}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | mat   | {english_stem} | english_stem | {mat}\n blank     | Space symbols   |       | {}             |              | \n blank     | Space symbols   | -   | {}             |              | \n asciiword | Word, all ASCII | it    | {english_stem} | english_stem | {}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | ate   | {english_stem} | english_stem | {ate}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}\n blank     | Space symbols   |       | {}             |              | \n asciiword | Word, all ASCII | rats  | {english_stem} | english_stem | {rat}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["For a more extensive demonstration, first create a ",(0,s.jsx)(n.code,{children:"public.english"})," configuration and Ispell dictionary for the English language:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"CREATE TEXT SEARCH CONFIGURATION public.english ( COPY = pg_catalog.english );\n\nCREATE TEXT SEARCH DICTIONARY english_ispell (\n    TEMPLATE = ispell,\n    DictFile = english,\n    AffFile = english,\n    StopWords = english\n);\n\nALTER TEXT SEARCH CONFIGURATION public.english\n   ALTER MAPPING FOR asciiword WITH english_ispell, english_stem;\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM ts_debug('public.english', 'The Brightest supernovaes');\n   alias   |   description   |    token    |         dictionaries          |   dictionary   |   lexemes   \n-----------+-----------------+-------------+-------------------------------+----------------+-------------\n asciiword | Word, all ASCII | The         | {english_ispell,english_stem} | english_ispell | {}\n blank     | Space symbols   |             | {}                            |                | \n asciiword | Word, all ASCII | Brightest   | {english_ispell,english_stem} | english_ispell | {bright}\n blank     | Space symbols   |             | {}                            |                | \n asciiword | Word, all ASCII | supernovaes | {english_ispell,english_stem} | english_stem   | {supernova}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["In this example, the word ",(0,s.jsx)(n.code,{children:"Brightest"})," was recognized by the parser as an ",(0,s.jsx)(n.code,{children:"ASCII"})," word (alias ",(0,s.jsx)(n.code,{children:"asciiword"}),"). For this token type the dictionary list is ",(0,s.jsx)(n.code,{children:"english_ispell"})," and ",(0,s.jsx)(n.code,{children:"english_stem"}),". The word was recognized by ",(0,s.jsx)(n.code,{children:"english_ispell"}),", which reduced it to the noun ",(0,s.jsx)(n.code,{children:"bright"}),". The word ",(0,s.jsx)(n.code,{children:"supernovaes"})," is unknown to the ",(0,s.jsx)(n.code,{children:"english_ispell"})," dictionary so it was passed to the next dictionary, and, fortunately, was recognized (in fact, ",(0,s.jsx)(n.code,{children:"english_stem"})," is a Snowball dictionary which recognizes everything; that is why it was placed at the end of the dictionary list)."]}),"\n",(0,s.jsxs)(n.p,{children:["The word ",(0,s.jsx)(n.code,{children:"The"})," was recognized by the ",(0,s.jsx)(n.code,{children:"english_ispell"})," dictionary as a stop word (",(0,s.jsx)(n.a,{href:"/docs/operate-with-data/sql-queries/full-text-search/text-search-dictionaries#stop-words",children:"Stop Words"}),") and will not be indexed. The spaces are discarded too, because the configuration provides no dictionaries at all for them."]}),"\n",(0,s.jsx)(n.p,{children:"You can reduce the width of the output by explicitly specifying which columns you want to see:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SELECT alias, token, dictionary, lexemes FROM ts_debug('public.english', 'The Brightest supernovaes'); \n  alias    |    token    |   dictionary   |    lexemes \n-----------+-------------+----------------+------------- \n asciiword | The         | english_ispell | {} \n blank     |             |                | \n asciiword | Brightest   | english_ispell | {bright} \n blank     |             |                | \n asciiword | supernovaes | english_stem   | {supernova}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"parser-testing",children:"Parser testing"}),"\n",(0,s.jsx)(n.p,{children:"The following functions allow direct testing of a text search parser."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"ts_parse(<parser_name> text, <document> text,\n         OUT <tokid> integer, OUT <token> text) returns setof record\nts_parse(<parser_oid> oid, <document> text,\n         OUT <tokid> integer, OUT <token> text) returns setof record\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"ts_parse"})," parses the given document and returns a series of records, one for each token produced by parsing. Each record includes a ",(0,s.jsx)(n.code,{children:"tokid"})," showing the assigned token type and a ",(0,s.jsx)(n.code,{children:"token"}),", which is the text of the token. For example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM ts_parse('default', '123 - a number');\n tokid | token\n-------+--------\n    22 | 123\n    12 |\n    12 | -\n     1 | a\n    12 |\n     1 | number\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"ts_token_type(<parser_name> text, OUT <tokid> integer,\n              OUT <alias> text, OUT <description> text) returns setof record\nts_token_type(<parser_oid> oid, OUT <tokid> integer,\n              OUT <alias> text, OUT <description> text) returns setof record\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"ts_token_type"})," returns a table which describes each type of token the specified parser can recognize. For each token type, the table gives the integer ",(0,s.jsx)(n.code,{children:"tokid"})," that the parser uses to label a token of that type, the ",(0,s.jsx)(n.code,{children:"alias"})," that names the token type in configuration commands, and a short ",(0,s.jsx)(n.code,{children:"description"}),". For example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SELECT * FROM ts_token_type('default');\n tokid |      alias      |               description                \n-------+-----------------+------------------------------------------\n     1 | asciiword       | Word, all ASCII\n     2 | word            | Word, all letters\n     3 | numword         | Word, letters and digits\n     4 | email           | Email address\n     5 | url             | URL\n     6 | host            | Host\n     7 | sfloat          | Scientific notation\n     8 | version         | Version number\n     9 | hword_numpart   | Hyphenated word part, letters and digits\n    10 | hword_part      | Hyphenated word part, all letters\n    11 | hword_asciipart | Hyphenated word part, all ASCII\n    12 | blank           | Space symbols\n    13 | tag             | XML tag\n    14 | protocol        | Protocol head\n    15 | numhword        | Hyphenated word, letters and digits\n    16 | asciihword      | Hyphenated word, all ASCII\n    17 | hword           | Hyphenated word, all letters\n    18 | url_path        | URL path\n    19 | file            | File or path name\n    20 | float           | Decimal notation\n    21 | int             | Signed integer\n    22 | uint            | Unsigned integer\n    23 | entity          | XML entity\n"})}),"\n",(0,s.jsx)(n.h2,{id:"dictionary-testing",children:"Dictionary testing"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"ts_lexize"})," function facilitates dictionary testing."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"ts_lexize(*dictreg* dictionary, *token* text) returns text[]\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"ts_lexize"})," returns an array of lexemes if the input ",(0,s.jsx)(n.code,{children:"*token*"})," is known to the dictionary, or an empty array if the token is known to the dictionary but it is a stop word, or ",(0,s.jsx)(n.code,{children:"NULL"})," if it is an unknown word."]}),"\n",(0,s.jsx)(n.p,{children:"Examples:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SELECT ts_lexize('english_stem', 'stars');\n ts_lexize\n-----------\n {star}\n\nSELECT ts_lexize('english_stem', 'a');\n ts_lexize\n-----------\n {}\n"})}),"\n",(0,s.jsxs)(n.admonition,{type:"note",children:[(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"ts_lexize"})," function expects a single token, not text. Here is a case where this can be confusing:"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SELECT ts_lexize('thesaurus_astro','supernovae stars') is null;\n ?column?\n----------\n t\n"})})]}),"\n",(0,s.jsxs)(n.p,{children:["The thesaurus dictionary ",(0,s.jsx)(n.code,{children:"thesaurus_astro"})," does know the phrase ",(0,s.jsx)(n.code,{children:"supernovae stars"}),", but ",(0,s.jsx)(n.code,{children:"ts_lexize"})," fails because it does not parse the input text but treats it as a single token. Use ",(0,s.jsx)(n.code,{children:"plainto_tsquery"})," or ",(0,s.jsx)(n.code,{children:"to_tsvector"})," to test thesaurus dictionaries, for example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-sql",children:"SELECT plainto_tsquery('supernovae stars');\n plainto_tsquery\n-----------------\n 'sn'\n"})})]})}function h(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>o,a:()=>a});var s=t(67294);const i={},r=s.createContext(i);function a(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);