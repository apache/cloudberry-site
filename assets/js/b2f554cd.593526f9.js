"use strict";(self.webpackChunkApache_Cloudberry_Incubating_website=self.webpackChunkApache_Cloudberry_Incubating_website||[]).push([[11477],{30010:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"welcoming-xungong-as-a-new-apache-cloudberry-committer","metadata":{"permalink":"/blog/welcoming-xungong-as-a-new-apache-cloudberry-committer","source":"@site/blog/2025-09-18-welcoming-xungong-as-a-new-apache-cloudberry-committer.md","title":"Welcoming Xun Gong as a New Apache Cloudberry Committer","description":"Becoming a committer demonstrates a strong commitment to the community.","date":"2025-09-18T00:00:00.000Z","formattedDate":"September 18, 2025","tags":[{"label":"Announcement","permalink":"/blog/tags/announcement"}],"readingTime":0.84,"hasTruncateMarker":true,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"welcoming-xungong-as-a-new-apache-cloudberry-committer","title":"Welcoming Xun Gong as a New Apache Cloudberry Committer","description":"Becoming a committer demonstrates a strong commitment to the community.","authors":["asfcloudberry"],"tags":["Announcement"],"image":"/img/blog/welcome-new-committer-blog-banner.png"},"unlisted":false,"nextItem":{"title":"What\'s New in Apache Cloudberry 2.0.0","permalink":"/blog/whats-new-in-apache-cloudberry-2.0.0"}},"content":"We\'re excited to welcome Xun Gong (GitHub ID: gongxun0928) as Apache Cloudberry\'s newest committer! \ud83c\udf89\\n\\n\x3c!-- truncate --\x3e\\n\\nXun has been a valuable contributor to the project, focusing on performance improvements and system reliability. His work spans query optimization, bug resolution, and enhancing core database features. Check out his contributions: [Xun\'s GitHub Activity](https://github.com/apache/cloudberry/commits?author=gongxun0928).\\n\\nWhat sets Xun apart is his thoughtful approach to code reviews and his ability to identify optimization opportunities that benefit the entire community. He brings both technical depth and a collaborative spirit that strengthens our development process.\\n\\nBecoming a committer is a recognition of both Xun\'s past contributions and the community\'s trust in his continued involvement. Committers play an important role in shaping the project by reviewing and merging contributions, participating in design decisions, and helping guide the project\'s growth.\\n\\nPlease join us in congratulating Xun on this well-deserved recognition. We look forward to his continued contributions and collaboration within the Apache Cloudberry community!\\n\\nYou can find the official announcement on the [Apache mailing list](https://lists.apache.org/thread/vn8k3dy2j11nv5bk3kryhjowv20ct73n)."},{"id":"whats-new-in-apache-cloudberry-2.0.0","metadata":{"permalink":"/blog/whats-new-in-apache-cloudberry-2.0.0","source":"@site/blog/2025-08-28-whats-new-in-apache-cloudberry-2.0.0.md","title":"What\'s New in Apache Cloudberry 2.0.0","description":"Dive into the new features and enhancements in Apache Cloudberry 2.0.0","date":"2025-08-28T00:00:00.000Z","formattedDate":"August 28, 2025","tags":[{"label":"Release","permalink":"/blog/tags/release"}],"readingTime":34.355,"hasTruncateMarker":false,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"whats-new-in-apache-cloudberry-2.0.0","title":"What\'s New in Apache Cloudberry 2.0.0","description":"Dive into the new features and enhancements in Apache Cloudberry 2.0.0","authors":["asfcloudberry"],"tags":["Release"],"image":"/img/blog/whats-new-in-apache-cloudberry-2.0.0.png"},"unlisted":false,"prevItem":{"title":"Welcoming Xun Gong as a New Apache Cloudberry Committer","permalink":"/blog/welcoming-xungong-as-a-new-apache-cloudberry-committer"},"nextItem":{"title":"Apache Cloudberry (Incubating) 2.0.0 Released","permalink":"/blog/announce-apache-cloudberry-2.0.0"}},"content":"Apache Cloudberry (Incubating) 2.0.0 is the first Apache release since joining the ASF Incubator. This major version delivers significant enhancements to the database kernel, representing a substantial leap forward in performance, reliability, and manageability. The release also includes hundreds of bug fixes and stability improvements.\\n\\nIn this article, we highlight only the most important features, enhancements, and fixes to help you quickly understand the key improvements in this release. For more details, please refer to the [Apache Cloudberry 2.0.0 Changelog](https://cloudberry.apache.org/releases/2.0.0-incubating/).\\n\\n## New features\\n\\n### Query processing and optimization\\n\\n#### Index and scan\\n\\n##### Enhanced index-only scan capabilities\\n\\n- Supports index-only scans on a broader range of index types when using the GPORCA optimizer, including those with covering indexes using `INCLUDE` columns. This helps improve query performance.\\n\\n- Supports dynamic index-only scan when using the GPORCA optimizer to accelerate queries on partitioned tables. This feature combines partition pruning with index-only access to avoid heap lookups, significantly reducing I/O and improving performance. It is ideal for wide tables with narrow covering indexes and can be enabled using `SET optimizer_enable_dynamicindexonlyscan = on`.\\n\\n- Supports index-only scans when using the GPORCA optimizer on append-only (AO) tables and PAX tables, enabling faster query execution by avoiding block access when possible. This improves performance in scenarios where traditional index scans on AO and PAX tables were previously inefficient.\\n\\n##### Improved index scan performance and flexibility\\n\\n- Supports backward index scans when using the GPORCA optimizer for queries with `ORDER BY ... DESC`, eliminating the need for explicit sorting when a B-tree index exists in the opposite order. This optimization reduces resource usage and improves performance, especially for top-N and pagination queries.\\n\\n- The GPORCA optimizer supports triggering Bitmap Index Scans using array comparison predicates like `col IN (...)` or `col = ANY(array)`, including for hash indexes. This improves query performance on large datasets by enabling more efficient multi-value matching. The optimizer automatically chooses the bitmap scan path based on cost estimation.\\n\\n- The GPORCA optimizer now considers the width of `INCLUDE` columns when costing index-only scans, favoring narrower indexes that return fewer unused columns. This improves plan selection for queries where multiple covering indexes are available. The cost model also more accurately estimates I/O by refining how `relallvisible` is used in index-only scan costing.\\n\\n##### BRIN index enhancements\\n\\n- Redesigns BRIN index internals for AO/CO tables to replace the `UPPER` page structure with a more efficient chaining model. This significantly reduces disk space usage for empty indexes and improves performance by avoiding unnecessary page access. The new design better handles the unique layout of AO/CO tables while maintaining correctness and compatibility.\\n\\n- BRIN indexes on AO/CO tables now support summarizing specific logical heap block ranges using `brin_summarize_range()`, enabling more precise control during index maintenance and testing. This enhancement also adds improved coverage for scenarios involving aborted rows, increasing robustness and correctness in edge cases.\\n\\n- Supports generating `IndexScan` plans when using the GPORCA optimizer with `ScalarArrayOp` qualifiers (for example, `col = ANY(array)`) for B-tree indexes. This enhancement aligns ORCA with the planner\'s behavior and allows more efficient execution of array comparison queries, as long as the predicate column is the first key in a multicolumn index.\\n\\n#### View and materialized view\\n\\n- Improves performance of `REFRESH MATERIALIZED VIEW WITH NO DATA` by avoiding full query execution. The command now behaves like a `TRUNCATE`,significantly reducing execution time while preserving proper dispatch to segments.\\n\\n#### Join\\n\\n- Supports left join pruning when using the GPORCA optimizer, allowing unnecessary left joins to be eliminated during query optimization. This applies when the query only uses columns from the outer table and the join condition fully covers the inner table\'s unique or primary keys. This can lead to more efficient query plans.\\n\\n- Supports `FULL JOIN` using the `Hash Full Join` strategy when using the GPORCA optimizer. This approach avoids sorting join keys and reduces data redistribution, making it suitable for large datasets or joins on non-aligned distribution keys. All `FULL JOIN` queries now use `Hash Full Join`.\\n\\n- The GPORCA optimizer now avoids unnecessary data redistribution for multi-way self joins using left or right outer joins when the join keys are symmetric. This optimization improves performance by recognizing that such joins preserve data colocation, eliminating redundant motion operations.\\n\\n- The GPORCA optimizer no longer penalizes broadcast plans for `NOT IN` queries (Left Anti Semi Join), regardless of the `optimizer_penalize_broadcast_threshold` setting. This change improves performance and avoids potential OOM issues by enabling parallel execution instead of concentrating large tables on the coordinator node.\\n\\n#### Function & aggregate\\n\\n- Supports intermediate aggregates when using the GPORCA optimizer, enabling more efficient execution of queries that include both `DISTINCT` aggregates and regular aggregates. This ensures correct handling of aggregation stages using `AGGSPLIT`. In addition, ORCA introduces an optimization for `MIN()` and `MAX()` functions by using index scans with a limit, instead of full table scans with regular aggregation. This optimization also supports `IS NULL` and `IS NOT NULL` conditions on indexed columns, significantly improving performance for applicable queries.\\n\\n- Enables more `HashAggregate` plan alternatives for queries that include `DISTINCT` aggregates when using the GPORCA optimizer. By generating a two-stage aggregation plan that avoids placing `DISTINCT` functions in hash-based nodes, ORCA ensures compatibility with the executor and expands the range of supported query plans. This improvement enhances optimization choices for group-by queries.\\n\\n- Supports queries using `GROUP BY CUBE`, enabling multi-dimensional grouping sets in query plans. This expands analytic query capabilities. Note that optimization time for `CUBE` queries may be high due to the large number of generated plan alternatives.\\n\\n#### Preprocessing\\n\\n- Inlines Common Table Expressions (CTEs) that contain outer references, allowing such queries to be planned and explained successfully. Previously, these queries would fall back to the legacy planner due to limitations in handling shared scans with outer references. This change improves compatibility and enables ORCA to optimize a broader range of CTE-based queries.\\n\\n- No longer rewrites `IN` queries to `EXISTS` when the inner subquery contains a set-returning function. This prevents invalid query transformations that could previously result in execution errors. The change ensures correct handling of queries like `a IN (SELECTgenerate_series(1, a))`.\\n\\n#### Optimization and performance enhancements\\n\\n##### Dynamic Table\\n\\n- Introduces dynamic tables, a new feature that enables automatic, scheduled refresh of query results. Dynamic tables are similar to materialized views but are designed for scenarios requiring up-to-date data, such as real-time analytics, lakehouse architectures, and automated ETL pipelines.\\n- Supports creating dynamic tables from base tables, external tables, or materialized views. Users can define refresh intervals using standard cron expressions, ensuring data is kept current without manual intervention.\\n- For more details, see the [official documentation](https://cloudberry.apache.org/docs/performance/use-dynamic-tables/).\\n\\n##### Plan hint\\n\\n- Supports plan hints for scan types and join row estimates when using the GPORCA optimizer, enabling users to guide query planning using `pg_hint_plan`-style comments. Supports scan hints include `SeqScan`, `IndexScan`, `BitmapScan`, and their negations, while row hints allow users to specify expected join cardinalities.\\n\\n- The `plan hint` field is now required in the ORCA optimizer configuration. This change simplifies internal parsing logic and ensures consistent handling of optimizer configuration files.\\n\\n- Supports join order hints for left and right outer joins when using the GPORCA optimizer, extending the existing hint framework beyond inner joins. This enhancement allows users to guide the optimizer\'s join order more precisely in complex queries involving outer joins, improving plan control and potentially execution performance.\\n\\n##### Enhancements to ORCA\\n\\n- Supports table aliases in query plans when using the GPORCA optimizer, making `EXPLAIN` outputs more descriptive and aligned with user-defined query syntax. In addition, ORCA adds support for query parameters, including those used in functions and prepared statements, enabling better compatibility with parameterized workloads and dynamic SQL execution.\\n\\n- When using the GPORCA optimizer, supports generating plans for queries on tables with row-level security (RLS) enabled. Security policies are enforced during plan generation, ensuring only permitted rows are visible to each user. ORCA still falls back to the planner for RLS queries with sublinks, foreign tables, or for `INSERT` and `UPDATE` statements.\\n\\n- The GPORCA optimizer now gracefully falls back to the Postgres planner when a function in the `FROM` clause uses `WITH ORDINALITY`, which is not currently supported. The fallback includes a clear error message indicating the unsupported feature.\\n\\n- When using the GPORCA optimizer, supports pushing down filters with `BETWEEN` predicates when combined with constant filters, enabling more effective predicate propagation. This enhancement can reduce the number of rows processed during joins, improving query performance in applicable cases.\\n\\n- When using the GPORCA optimizer, supports hashed subplans when the subquery expression is hashable and contains no outer references. This enhancement can significantly improve query performance by reducing execution time in applicable cases.\\n\\n- ORCA now supports executing foreign tables with `mpp_execute=\'ANY\'` on either the coordinator or segments, depending on cost. This allows more flexible and efficient execution plans for foreign data sources. A new \\"Universal\\" distribution type is introduced to support this behavior, similar to how `generate_series()` is handled.\\n\\n- ORCA now supports direct dispatch for randomly distributed tables when the query includes a filter on `gp_segment_id`. This enhancement improves query performance by routing execution directly to the relevant segment, reducing unnecessary data processing across the cluster.\\n\\n- ORCA now supports generating plans with the `ProjectSet` node, enabling correct execution of queries that include set-returning functions (SRFs) in the target list. This enhancement prevents fallback to the legacy planner and ensures compatibility with PostgreSQL 11+ behavior.\\n\\n- ORCA now supports the `FIELDSELECT` node, which allows it to optimize a broader range of queries involving composite data types. Previously, such queries would fall back to the legacy planner. This enhancement improves compatibility and reduces unnecessary planner fallbacks.\\n\\n- ORCA now derives statistics only for the columns used in `UNION ALL` queries, instead of all output columns from the input tables. This optimization reduces unnecessary computation and can improve planning performance for large queries.\\n\\n- Updates naming in logs and `EXPLAIN` output to refer to the optimizers as \\"GPORCA\\" and \\"Postgres based planner\\" for improved clarity and consistency.\\n\\n- Optimizes ORCA\'s `Union All` performance by deriving statistics only for columns used in the query output. This reduces unnecessary computation and improves planning efficiency for queries with unused columns.\\n\\n### Transaction management\\n\\n#### Lock management\\n\\n- Updates logic to ignore invalidated slots while computing the oldest catalog Xmin, reducing the risk of deadlocks and improving transaction concurrency.\\n\\n- Performs serializable isolation checks early for AO/CO tables, ensuring stricter consistency guarantees and reducing the likelihood of isolation conflicts.\\n\\n- Enhances the index creation process to prevent deadlocks by ensuring the coordinator acquires an `AccessShareLock` on `pg_index` before dispatching a synchronization query to segments, thus aligning `indcheckxmin` and avoiding conflicts that GDD cannot resolve.\\n\\n#### Transaction performance and reliability\\n\\n- Avoids replaying DTX information in checkpoints for newly expanded segments, preventing potential inconsistencies during recovery.\\n\\n- Adds `gp_stat_progress_dtx_recovery` for better observability of distributed transaction recovery progress.\\n\\n- Improves error reporting for DTX protocol command dispatch errors, making it easier to diagnose and resolve issues.\\n\\n- Allows utility mode on the coordinator to skip upgrading locks for `SELECT` locking clauses, improving efficiency for maintenance operations.\\n\\n### Storage\\n\\n#### PAX table format\\n\\n- Introduces support for the PAX (Partition Attributes Across) storage format, a hybrid approach that combines the advantages of row-based and column-based storage. PAX is designed to deliver high performance for both data writes and analytical queries, making it well-suited for OLAP workloads and large-scale data analysis. For more details, see the [official documentation](https://cloudberry.apache.org/docs/operate-with-data/pax-table-format/).\\n\\n#### AO/CO table enhancements\\n\\n- Optimizes `CREATE INDEX` operations on AO tables with scan progress reporting, enhancing the efficiency of index creation.\\n\\n- Declares the connected variable as \\"volatile\\" to ensure proper handling across `PG_TRY` and `PG_CATCH` blocks, mirroring PostgreSQL\'s best practices for exception-safe variable usage in transaction control.\\n\\n#### Partitioning\\n\\n- Extends Orca\'s planning capabilities to include support for foreign partitions, enabling optimized query execution for tables with a mix of foreign and non-foreign partitions. The implementation introduces new logical and physical operators for foreign partitions, supports static and dynamic partition elimination, and integrates with any foreign data wrapper compatible, enhancing performance and flexibility for external data queries.\\n\\n- Optimizes the analysis of leaf partitions in multi-level partition tables to avoid unnecessary resampling of intermediate partitions.\\n\\n- Supports dynamic partition elimination (DPE) when using the GPORCA optimizer for plans involving duplicate-sensitive random motions. This allows partition selectors to pass through segment filters, enabling more efficient query plans and reducing the number of scanned partitions.\\n\\n- Adds Dynamic Partition Elimination for Hash Right Joins, which enhances the efficiency of join operations on partitioned tables.\\n\\n- Supports boolean static partition pruning in ORCA, enhancing the efficiency of partition pruning during query optimization.\\n\\n- Enhances ORCA\'s query planning by incorporating partition key opfamily checks during partition pruning to optimize data distribution and partition scanning, ensuring correct motion triggering and partition scanning by aligning predicate operators with the distribution or partition key\'s opfamily, addressing issues with missing motion, incorrect direct dispatch, and ineffective partition pruning.\\n\\n- Caches the last found partition in `ExecFindPartition` to improve performance for repeated partition lookups.\\n\\n- Enables ORCA to derive dynamic table scan cardinality from leaf partitions, addressing limitations in handling date and time-related data types by changing their internal representation to doubles.\\n\\n- Enhances the DPv2 algorithm to include distribution spec information with partition selectors, improving the efficiency of distributed query execution.\\n\\n- Introduces a new Non-Replicated distribution specification to optimize join operations in database processing. By relaxing the enforcement of singleton distribution for outer tables when the inner table is universally distributed, it aims to reduce unnecessary data gathering and duplicate-sensitive motions, thereby generating more efficient execution plans.\\n\\n#### Memory management\\n\\n- Implements a custom allocator to enable ORCA to use standard C++ containers, addressing heap allocation management.\\n\\n- Refactors ORCA\'s memory pool by making several methods static and adds assertions to ensure pointer safety.\\n\\n- Optimizes serialization of IMDId objects in ORCA to be lazy, improving performance by deferring serialization until necessary. Improves optimization time when loading objects into the relcache and when involving large and wide partition tables.\\n\\n- Ensures that strings returned by `GetDatabasePath` are always freed using `pfree`, preventing memory leaks.\\n\\n- Enables MPP (Massively Parallel Processing) support for `pg_buffercache` and builds it by default, making buffer cache management more scalable and efficient in distributed environments.\\n\\n- Introduces `pg_buffercache_summary()` to offer a high-level overview of buffer cache activity.\\n\\n#### Metadata and access methods\\n\\n- Allows the definition of lock modes for custom reloptions, providing more control over table and index access.\\n\\n- Supports specification of reloptions when switching storage models, allowing seamless transitions between different storage formats.\\n\\n- Introduces a new struct member in `CreateStmt` to indicate the origin of the statement, specifying if it was generated from GP style classic partitioning syntax.\\n\\n- Adds syscache lookup for `pg_attribute_encoding` and `pg_appendonly`, improving performance and efficiency in metadata access.\\n\\n- Introduces a new catalog entry in `pg_aggregate` to store replication safety information for aggregates, allowing users to mark specific aggregates as safe for execution on replicated slices via an optional repsafe parameter during the `CREATE AGGREGATE` command. This helps optimize performance by avoiding unnecessary broadcasts on large replicated datasets.\\n\\n- Enhances the dispatch of `ALTER DATABASE` commands by allowing options like `ALLOW_CONNECTIONS` and `IS_TEMPLATE` to be dispatched to segments, ensuring catalog changes are reflected everywhere.\\n\\n### Data loading and external tables\\n\\n#### External table enhancements\\n\\n- Adds clearer restrictions and warnings when exchanging or attaching external tables. Writable external tables can no longer be used as partitions, and attaching readable external tables without validation now triggers a warning instead of requiring a no-op clause.\\n\\n- Disables `SET DISTRIBUTED REPLICATED` for `ALTER EXTERNAL TABLE` to prevent misuse and ensure consistency.\\n\\n#### Foreign data wrapper\\n\\n- Improves performance and stability for `gpfdist` external tables. Adds TCP keepalive support for more reliable reads, and increases the default buffer size to enhance write throughput for writable external tables.\\n\\n- ORCA now falls back to the planner for queries involving foreign partitions using `greenplum_fdw`, preventing crashes caused by incompatible execution behavior. Queries on non-partitioned foreign tables using `greenplum_fdw` remain supported by ORCA.\\n\\n### High availability and high reliability\\n\\n#### Backup and disaster recovery\\n\\n- Improves archiver performance when handling many `.ready` files by reducing redundant directory scans. This change speeds up WAL archiving, especially when `archive_command` has been failing and many files have accumulated.\\n\\n- `gp_create_restore_point()` can only be executed on the Coordinator node. Calling this function on a segment node will result in an error. The function returns a structured record value, including the restore point name and LSN, which you can view directly by running `SELECT * FROM gp_create_restore_point()`.\\n\\n#### WAL\\n\\n- Improves WAL replication management by restricting a coordinator-specific tracking mechanism to the coordinator only. This change simplifies primary segment behavior and aligns replication practices more closely across segments. No functional change for users, but helps reduce unnecessary complexity in WAL retention logic.\\n\\n- Enhances WAL retention logic to improve reliability of incremental recovery using `pg_rewind`. Physical replication slots now retain WAL files up to the last common checkpoint, reducing risk of missing WAL during recovery. This change also simplifies the underlying logic and adds test coverage for WAL recycling.\\n\\n- Switches WAL replication connections to use the standard libpq protocol instead of a legacy internal one. This improves compatibility and reliability of replication behavior. Also fixed test failures and improved error handling for replication connections.\\n\\n### Security\\n\\n#### DB Operations\\n\\n- `REFRESH MATERIALIZED VIEW CONCURRENTLY` runs all internal operations in the correct security context to prevent potential privilege escalation. This change ensures safer execution by restricting operations to the appropriate permission level.\\n\\n- Improves internal handling of new `aoseg` and `aocsseg` tuples by aligning tuple freezing behavior with other catalog operations. This change enhances consistency with upstream PostgreSQL practices and removes the need for `CatalogTupleFrozenInsert`.\\n\\n#### System processes\\n\\n- Orphaned file checks now exclude idle sessions during safety validation. This prevents unnecessary errors when persistent connections from services are active, allowing the detection process to complete successfully.\\n\\n- Adds a safety check in backend signal handlers to ensure signals are handled by the correct process. This prevents unintended shared memory access by child processes and improves overall process isolation and stability.\\n\\n- Improves process safety by preventing child processes spawned via `system()` from calling `proc_exit()`. This avoids potential corruption of shared memory structures and ensures only the parent process performs cleanup operations.\\n\\n- Removes the permission check for `cpu.pressure` when using `gp_resource_manager=\'group-v2\'`. This prevents startup failures on systems where PSI is disabled, without affecting resource management functionality.\\n\\n#### Replication/Mirrorless clusters\\n\\n- Improves replication error reporting by setting persistent `WalSndError` when a replication slot is invalidated. This ensures accurate error visibility in `gp_stat_replication`.\\n\\n#### Permission management\\n\\n- Strengthens security by rejecting extension schema or owner substitutions containing potentially unsafe characters like `$`, `\'`, or `\\\\`. This prevents SQL injection in extension scripts and protects against privilege escalation in certain non-bundled extensions.\\n\\n- Creating or assigning roles to the `system_group` resource group now results in an error, as this group is reserved for internal system processes only.\\n\\n- Reverts the restriction requiring superuser privileges to set the `gp_resource_group_bypass` GUC. This allows applications like GPCC to function more easily while still limiting resource impact.\\n\\n- Altering the `mpp_execute` option of a foreign server or wrapper is now disallowed to prevent inconsistencies in foreign table distribution policies. Changing these options previously could result in outdated cached plans and incorrect query execution. This update ensures plan correctness by enforcing cache invalidation only when appropriate.\\n\\n#### pgcrypto\\n\\n- Adds support for FIPS mode in `pgcrypto`, controlled by a GUC. This allows Cloudberry to operate in FIPS-compliant environments when linked with a supported FIPS-enabled OpenSSL version. Certain ciphers are disabled in this mode to comply with FIPS requirements.\\n\\n- `pgcrypto` now allows enabling FIPS mode even on systems where FIPS is not pre-enabled by the OS or environment. This change removes the dependency on `FIPS_mode()` checks, offering more flexibility in managing FIPS compliance through the database.\\n\\n### Resource management\\n\\n#### Resource group management\\n\\n- Renames the `memory_limit` parameter to `memory_quota` in `CREATE/ALTER RESOURCE GROUP` to clarify its meaning and unit.\\n\\n- Adds a new system view `gp_toolkit.gp_resgroup_status_per_segment` to monitor memory usage per resource group on each segment. This view helps database administrators track real-time vmem consumption (in MB) when resource group-based resource management is enabled.\\n\\n- Improves logging behavior when memory usage reaches Vmem or resource group limits. The system now prints log messages directly to stderr to avoid stack overflow errors during allocation failures.\\n\\n- Removes unnecessary permission check for `cpu.pressure` when using the `group-v2` resource manager. This prevents startup failures on systems where PSI is not enabled, improving compatibility across Linux distributions.\\n\\n#### Logging and monitoring\\n\\n- Adds additional log messages for GDD backends to help investigate memory-related issues. These logs provide better visibility into backend behavior during high memory usage scenarios.\\n\\n- Adds a log ignore rule for \\"terminating connection\\" messages to reduce noise in test outputs. This helps avoid unnecessary diffs in CI for tests that involve connection termination.\\n\\n- Adds more verbose logging to `ResCheckSelfDeadlock()`.\\n\\n- Logs queue IDs and portal IDs in resource queue logs.\\n\\n- Dumps more information when releasing resource queue locks to aid in troubleshooting and monitoring.\\n\\n- Uses `ERROR` for dispatcher liveness checks.\\n\\n- Enhances logging for dispatch connection liveness checks to improve clarity during connection failures. Logs now include more accurate error messages based on socket state and system errors.\\n\\n#### Platform compatibility and build\\n\\n- Improves `gp_sparse_vector` compatibility with ARM platforms by fixing type handling in serialization logic. This ensures consistent behavior across different architectures.\\n\\n- Adds support for `sigaction()` on Windows to align signal handling behavior with other platforms. This reduces platform-specific differences and improves code consistency.\\n\\n- Updates ACL mode type in ORCA to match the parser\'s definition, ensuring consistent type usage.\\n\\n#### System views and statistics\\n\\n- Improves join cardinality estimation for projected columns that preserve the number of distinct values (NDVs), such as additions or subtractions with constants. This allows the optimizer to use underlying column histograms for more accurate estimates, improving plan quality for queries with scalar projections in join conditions.\\n\\n- Increases precision for frequency and NDV values in ORCA when processing metadata population scripts (MDPs). This change ensures consistent behavior between MDPs and live database queries, reducing discrepancies caused by rounding small values.\\n\\n- ORCA now considers null value skew when costing redistribute motions, improving plan accuracy for queries involving columns with many nulls. This helps avoid performance issues caused by data being unevenly distributed across segments.\\n\\n- ORCA now supports extended statistics to improve cardinality estimation for queries with correlated columns. This allows the optimizer to use real data-driven correlation factors instead of relying on arbitrary GUC settings, leading to more accurate query plans.\\n\\n- Introduces `gp_log_backend_memory_contexts` to log memory contexts across segments, with optional targeting by content ID. This enhances observability and helps diagnose memory issues in distributed queries.\\n\\n- ORCA now supports statistics derivation for predicates involving different time-related data types, such as date and timestamp. This improves plan accuracy and performance for queries comparing mixed temporal types.\\n\\n- Autostats now uses `SKIP LOCKED` for `ANALYZE` operations to avoid blocking on locks, reducing the risk of deadlocks and improving predictability. This behavior is enabled by default and can be controlled using the `gp_autostats_lock_wait` GUC.\\n\\n- ORCA now supports `STATS_EXT_NDISTINCT` extended statistics for estimating cardinality on correlated columns. This improves accuracy for queries using `GROUP BY` or `DISTINCT` on such columns.\\n\\n#### Network connections\\n\\n- Marks `gp_reject_internal_tcp_connection` as defunct to improve reliability of internal QD-to-entry DB connections. These connections over TCP/IP are now treated as authenticated by default, preventing authentication errors caused by `pg_hba.conf` settings.\\n\\n### Tools and utilities\\n\\n#### analyzedb\\n\\n- `analyzedb` now includes materialized views in its list of tables to analyze. This improves the performance immediately after analysis.\\n\\n#### gpexpand\\n\\n- `gpexpand` now includes a cluster health check to ensure all segments are up and in their preferred roles before proceeding. This prevents incorrect port assignments and avoids potential issues during expansion when nodes are not in a stable state.\\n\\n#### gp_toolkit\\n\\n- Added an update path for the `gp_toolkit` extension to version 1.6. This update renames the column `memory_limit` to `memory_quota` in the `gp_resgroup_config` view for improved clarity. Users can apply the update using `ALTER EXTENSION gp_toolkit UPDATE TO \'1.6\'`.\\n\\n## Bug fixes\\n\\n- Fixed data loss caused by incorrect shared snapshot handling.\\n- Fixed memory corruption during AOCO ADD COLUMN abort.\\n- Fixed checkpoint WAL replay failure.\\n- Fixed incorrect results when using UNION for RECURSIVE_CTE.\\n- Fixed incorrect results from hash joins on char columns.\\n- Fixed incorrect results produced by WITH RECURSIVE queries.\\n- Fixed incorrect results when a REPLICATED table is unioned with a DISTRIBUTED table.\\n- Fixed incorrect results when the outer query had ORDER BY after a LATERAL subquery.\\n- Fixed incorrect behavior of DELETE with split update.\\n- Fixed incorrect results when using direct dispatch.\\n- Fixed memory leaks in ORCA and various components.\\n- Fixed long-running execution with bitmap indexes.\\n- Fixed redundant SORT enforcement on group aggregates.\\n- Fixed incorrect index position in target list in ExecTupleSplit.\\n- Fixed incorrect value in the cpu_usage column returned by `pg_resgroup_get_status()`.\\n- Fixed incorrect behavior of gp_toolkit.gp_move_orphaned_files.\\n- Fixed incorrect results in multi-stage aggregate queries.\\n- Fixed incorrect plan and output in multi-stage aggregate queries.\\n- Fixed incorrect reltuples value after VACUUM.\\n- Fixed incorrect index->reltuples value after VACUUM.\\n- Fixed a vulnerability where LDAP leaked user information.\\n- Fixed incorrect permissions warning on the pgpass file.\\n- Fixed incorrect handling of ONLY keyword for multiple tables in GRANT/REVOKE statements.\\n- Fixed incorrect permissions in resource management DDL.\\n- Fixed incorrect security context in REFRESH MATERIALIZED VIEW CONCURRENTLY.\\n- Fixed deadlock between coordinator and segments.\\n- Fixed race condition in CTE reader-writer communication.\\n- Fixed race condition when invalidating obsolete replication slots.\\n- Fixed deadlock by allowing concurrent creation of non-first indexes on AO tables.\\n- Fixed locking issue when opening range tables inside `ExecInitModifyTable()`.\\n- Fixed incorrect unlock mode in DefineRelation.\\n- Fixed incorrect locking in partition distribution policies.\\n- Fixed issues with rle_type when converting a table from AO to AOCO.\\n- Fixed incorrect handling of empty ranges and NULL values in BRIN indexes.\\n- Fixed incorrect handling of NULL values when merging BRIN summaries.\\n- Fixed incorrect TIDs order when building bitmap indexes.\\n- Fixed possible inconsistency between bitmap LOV table and its index.\\n- Fixed incorrect behavior of VACUUM in AO tables with indexes.\\n- Fixed incorrect handling of TOAST values for invisible AppendOptimized tuples during VACUUM.\\n- Fixed ORCA\'s invalid processing of nested SubLinks under aggregates.\\n- Fixed ORCA\'s invalid processing of nested SubLinks referenced in GROUP BY clauses.\\n- Fixed ORCA\'s invalid processing of nested SubLinks with GROUP BY attributes.\\n- Fixed incorrect predicate pushdown when using casted columns.\\n- Fixed incorrect join condition loss after pulling up sublinks to join nodes.\\n- Fixed incorrect hash-key generation for Redistribute Motion in multi-DQA expressions.\\n- Fixed incorrect plan generation for SEMI JOIN with RANDOM distributed tables.\\n- Fixed incorrect behavior of gp_stat_bgwriter.\\n- Fixed incorrect monitoring in pg_stat_slru.\\n- Fixed incorrect monitoring in gp_stat_progress_dtx_recovery.\\n- Fixed incorrect monitoring in pg_resgroup_get_status().\\n- Fixed incorrect monitoring in gp_toolkit.gp_resgroup_config.\\n- Fixed compilation issues on various platforms.\\n- Fixed documentation and comment typos.\\n- Fixed build system and Makefile issues.\\n- Fixed various memory leaks and resource management issues.\\n- Fixed various error handling and logging improvements.\\n- Fixed mismatched types.\\n- Fixed the ORCA preprocess step for queries with the Select-Project-NaryJoin pattern.\\n- Fixed the missing discard_output variable in shared scan node functions.\\n- Fixed the crash caused by running VACUUM AO_AUX_ONLY on an AO-partitioned table.\\n- Fixed an obvious memory leak in _bitmap_xlog_insert_bitmapwords().\\n- Fixed a memory leak in the merge join implementation.\\n- Fixed the issue where the token for user ID xxx did not exist.\\n- Fixed the issue where plan hints could not derive table descriptors.\\n- Fixed the issue where inject_fault suspend could not be canceled.\\n- Fixed fallback in debug builds due to scalars with invalid return types.\\n- Fixed relptr encoding of the base address.\\n- Fixed visimap consults for unique checks during UPDATE operations.\\n- Fixed the issue where external table location URIs containing | caused errors.\\n- Fixed handling of the time command output containing commas.\\n- Fixed a small overestimation of the output length of base64 encoding.\\n- Fixed gp_toolkit.__gp_aocsseg_history crash on non-AO columnar tables.\\n- Fixed a race condition between termination and resqueue wakeup.\\n- Fixed a statement leak involving self-deadlocks.\\n- Fixed the detection of child output columns when the parent is a UNION during join pruning.\\n- Fixed a query crash when using a negative memory_limit value in resource groups.\\n- Fixed issues in pgarch new directory-scanning logic.\\n- Fixed a memory leak in the FTS PROBE process.\\n- Fixed check_multi_column_list_partition_keys.\\n- Fixed a memory leak caught via ICW with memory check enabled.\\n- Fixed query hang and fallback issues involving CTEs on replicated tables.\\n- Fixed the unrecognized join type error with LASJ Not-In and network types.\\n- Fixed issues in upgrade_adapt.sql related to queries using WITH OIDS.\\n- Fixed the double declaration of check_ok() in pg_upgrade.h.\\n- Fixed logic error with subdirectories generated by pg_upgrade for internal files.\\n- Fixed a typo in the pg_upgrade file header.\\n- Fixed the bug where PL/Python functions caused the master process to reset.\\n- Fixed the Shared Scan hang issue involving initplans.\\n- Fixed motion toast error.\\n- Fixed a memory leak related to fsync in AO tables.\\n- Fixed CDatumSortedSet handling of empty arrays that caused errors in ORCA.\\n- Fixed ORCA returning incorrect column type modifier information.\\n- Fixed DbgStr output when printing DP structs in ORCA.\\n- Fixed the comment on performDtxProtocolPrepare.\\n- Fixed a memory leak in Dynamic Index, IndexOnly, and BitmapIndex scans during execution.\\n- Fixed the memory accounting bug when moving MemoryContext under another accounting node.\\n- Fixed the ALTER TABLE ALTER COLUMN TYPE issue that reuses an incorrect index.\\n- Fixed query fallback when a subquery is present within LEAST() or GREATEST().\\n- Fixed the typo in timestamp.\\n- Fixed unexpected warnings related to pg_stat_statements node types.\\n- Fixed the crash involving initplan in MPP.\\n- Fixed LeftJoinPruning pruning essential LEFT JOINs.\\n- Fixed the SET command that incorrectly sends DTX protocol commands.\\n- Fixed the segmentation fault in addOneOption().\\n- Fixed parallel_retrieve_cursor diffs.\\n- Fixed gpdiff.pl to ignore information when EXPLAIN ignores costs.\\n- Fixed the uninitialized-use warning in CTranslatorDXLToPlStmt.cpp.\\n- Fixed the bug where the LOCALE flag cannot be used with a string pattern.\\n- Fixed a typo in cdbmutate.c.\\n- Fixed CColRefSet debug printing.\\n- Fixed ORCA producing incorrect plans when handling SEMI JOIN with RANDOM distributed tables.\\n- Fixed orphaned temp tables on the coordinator.\\n- Fixed the segmentation fault caused by concurrent INSERT ON CONFLICT and DROP TABLE.\\n- Fixed redundant columns in a multi-stage aggregate plan.\\n- Fixed the import of ICU collations in pg_import_system_collations().\\n- Fixed the error: \\"Cannot add cell to table content: total cell count of XXX exceeded.\\"\\n- Fixed orphaned temporary namespace catalog entries left on the coordinator.\\n- Fixed REFRESH MATERIALIZED VIEW on AO tables with indexes.\\n- Fixed the use of PORTNAME in the gp_toolkit Makefile.\\n- Fixed pg_stat_activity display for bypassed and unassigned queries.\\n- Fixed the recursive CTE MergeJoin that involved a motion on WTS.\\n- Fixed the column width display for partitioned tables.\\n- Fixed the LDAP crash when ldaptls=1 and ldapscheme is not set.\\n- Fixed the gpstop pipeline flakiness after the referenced change.\\n- Fixed the ANALYZE bug in expand_vacuum_rels.\\n- Fixed the compilation error.\\n- Fixed the ORCA crash due to improper colref mapping with CTEs.\\n- Fixed the bug where gpload insert mode was not included in a transaction.\\n- Fixed the bug where resgroup total wait time was always zero.\\n- Fixed the gpcheckcat error against pg_description.\\n- Fixed flakiness caused by waiting for a different number of fault triggers.\\n- Fixed the bug involving RelabelType in the GROUP BY clause.\\n- Fixed the planner error with multiple copies of an AlternativeSubPlan.\\n- Fixed the issue with bitmap indexes.\\n- Fixed the bug in HashAgg related to selective-column-spilling logic.\\n- Fixed the bug in disk-based hash aggregation.\\n- Fixed the pipeline stall issue in LookupTupleHashEntryHash().\\n- Fixed the use of version in ArgumentParser, which is deprecated.\\n- Fixed the use of BaseException.message, which has been deprecated since Python 2.6.\\n- Fixed the case pg_rewind_fail_missing_xlog.\\n- Fixed the compiler warning for gcc-12.\\n- Fixed support for the DEFERRABLE keyword on primary and unique keys.\\n- Fixed the unlocking of pruned partitions in partitioned tables.\\n- Fixed the crash in ORCA involving skip-level correlated queries.\\n- Fixed the removal of Assert statements in release builds.\\n- Fixed the typo in comments: JOIN_SEMI_DEDUP/JOIN_SEMI_DEDUP_REVERSE.\\n- Fixed the issue where REORGANIZE=TRUE did not redistribute randomly-distributed tables.\\n- Fixed the core dump caused by concurrent updates on partition tables in DynamicScan.\\n- Fixed the typo: ANALZE to ANALYZE.\\n- Fixed the issue where cgroup v1 cpu_quota_us cannot be larger than its parent\'s value.\\n- Fixed indentation and trailing whitespace in UDFs in resgroup/resgroup_auxiliary_tools_v1.\\n- Fixed the name of cpu_hard_quota_limit in resgroup_syntax.sql.\\n- Fixed multi-row DEFAULT handling in INSERT ... SELECT rules.\\n- Fixed invalid function references in several comments.\\n- Fixed the bug where COPY FORM does not throw ERROR: extra data after last expected column.\\n- Fixed the issue where file .204800 was not being checked in ao_foreach_extent_file.\\n- Fixed the issue of incorrectly incrementing the command counter.\\n- Fixed the coordinator crash in MPPnoticeReceiver.\\n- Fixed the dangling pointer in ExecDynamicIndexScan().\\n- Fixed the ORCA bug that incorrectly removed required redistribution motion when using GROUP BY over gp_segment_id.\\n- Fixed header handling in url_curl.c.\\n- Fixed ao_filehandler to support new attnum to filenum mapping changes.\\n- Fixed pg_aocsseg to work with attnum to filenum mapping.\\n- Fixed a comment in pg_dump.\\n- Fixed the ORCA build break.\\n- Fixed the gpconfig SSH retry undefined parameter issue.\\n- Fixed the stale gp_default_storage_options comment.\\n- Fixed the bug: unrecognized node type: 147.\\n- Fixed spelling errors identified by lintian.\\n- Fixed the bypass catalog unit test.\\n- Fixed erroneous Valgrind markings in AllocSetRealloc.\\n- Fixed the legacy bug in the DatabaseFrozenIds lock.\\n- Fixed the mirror checkpointer error on the ALTER DATABASE query.\\n- Fixed the bug: get_ao_compression_ratio() failed on root partitioned tables with AO children.\\n- Fixed the issue where InterruptHoldoffCount was not being reset.\\n- Fixed gpexpand failure caused by an event trigger.\\n- Fixed missing redistribute for CTAS or INSERT INTO on randomly distributed tables when using ORCA.\\n- Fixed the double free of remapper->typmodmap in TeardownUDPIFCInterconnect().\\n- Fixed the bug in the upstream-merged COMMIT AND CHAIN feature.\\n- Fixed inconsistency between gp_fastsequence row and index after a crash.\\n- Fixed the typo allocatd to allocated.\\n- Fixed the error: unrecognized node type: 145 in transformExpr.\\n- Fixed build error caused by unused variable.\\n- Fixed the issue where the distribution key was missing when creating a stage table.\\n- Fixed the regex for etc/environment.d.\\n- Fixed the string comparison warning.\\n- Fixed obsolete references to SnapshotNow in comments.\\n- Fixed pull-up error when the target list contains a RelabelType node.\\n- Fixed the issue where index DDL operations were recorded in QEs\' pg_last_stat_operation.\\n- Fixed two compiler warnings.\\n- Fixed the wrong value of maxAttrNum in TupleSplitState.\\n- Fixed the bug of incorrect index position in target list in ExecTupleSplit.\\n- Fixed the format error of the library name on Mac M1.\\n- Fixed the pg_resgroup_get_status_kv() function.\\n- Fixed interconnect bugs in ic_proxy_ibuf_push().\\n- Fixed memory leaks in auto_explain.\\n- Fixed ic_proxy compilation when HOST_NAME_MAX is unavailable.\\n- Fixed duplicate filters caused by reversed operator argument order.\\n- Fixed pg_rewind when the log file is a symbolic link.\\n- Fixed and enabled 64-bit bitmapset and updated visimap.\\n- Fixed the hang caused by multi-DQA with filters in the planner.\\n- Fixed the bogus ORCA plan that incorrectly joins a CTE and a REPLICATED table.\\n- Fixed the error in ATSETAM when applied to ao_column with a dropped column.\\n- Fixed the LWLockHeldByMe assert failure in SharedSnapshotDump.\\n- Fixed the KeepLogSeg() unit test.\\n- Fixed the race condition when invalidating obsolete replication slots.\\n- Fixed the uninitialized value in segno calculation.\\n- Fixed issues in the invalidation logic for obsolete replication slots.\\n- Fixed checkpoint signalling.\\n- Fixed memory overrun when querying pg_stat_slru.\\n- Fixed the bug where ORCA fails to decorrelate subqueries ordered by outer references.\\n- Fixed unused variable compile warnings.\\n- Fixed the bug where NestLoop join fails to materialize the inner child in some cases.\\n- Fixed COPY execution via FDW on coordinator as executor.\\n- Fixed inFunction usage for auto_stats in CTAS.\\n- Fixed a compiler warning.\\n- Fixed the syntax error with CREATE MATERIALIZED VIEW.\\n- Fixed the issue preventing temporary table creation LIKE existing tables with comments.\\n- Fixed and rewrote IndexOpProperties API.\\n- Removed redundant Get/SetStaticPruneResult usage.\\n- Fixed EPQ handling for DML operations.\\n- Fixed gpcheckperf failure when using -V with -f option.\\n- Fixed possible mirror startup failure triggered by FTS promotion.\\n- Fixed the parallel retrieve cursor issue when selecting transient record types.\\n- Fixed the resource management DDL warning: unrecognized node type when log_statement=\'ddl\'\\n- Fixed the resgroup init error when many cores are present in cpuset.cpus.\\n- Fixed resqueue malfunction when using JDBC extended protocol.\\n- Fixed the missing LOCKING CLAUSE on foreign tables when ORCA is enabled.\\n- Fixed the test_consume_xids behavior where it consumes one more transaction ID than expected.\\n- Fixed the ONLY keyword handling for multiple tables in GRANT/REVOKE statements.\\n- Fixed the regression test to ignore memory usage values in JSON format EXPLAIN output.\\n- Fixed relcache lookup in ORCA when selecting from sequences.\\n- Fixed missing WAL files required by pg_rewind.\\n- Fixed the gp_dqa test to explicitly ANALYZE tables.\\n- Fixed the crash of AggNode in the executor caused by an ORCA plan.\\n- Fixed the resource group cpuset test case.\\n- Fixed the compiler warning caused by gpfdist with compressed external tables.\\n- Fixed link issues on macOS and Windows.\\n- Fixed failure when DynamicSeqScan contains a SubPlan.\\n- Fixed the error: cache lookup failed for type 0.\\n- Fixed the multi-level correlated subquery bug.\\n- Fixed checkpoint WAL replay failure.\\n- Fixed the check for BufFileRead() in ExecHashJoinGetSavedTuple().\\n- Fixed the test extension to allow executing SQL code inside a Portal.\\n- Fixed resgroup view test cases.\\n- Fixed incorrect DISTKEY assignment when copying partitions on segments.\\n- Fixed ic-proxy mis-disconnecting addresses after reloading the config file.\\n- Fixed the gpcheckcat check on partition distribution policies.\\n- Fixed colid remapping in disjunctive constraints.\\n- Fixed the Makefile by removing the tablespace-step target from all.\\n- Fixed CBitSet intersection logic in ORCA.\\n- Fixed the query preprocessor for nested Select-Project-NaryJoin patterns.\\n- Fixed incorrect unlock mode in DefineRelation.\\n- Fixed the upgrade process for external tables with dropped columns.\\n- Fixed the formatting issue in SECURITY.md.\\n- Fixed gp_gettmid to return the correct startup timestamp.\\n- Fixed the gpload regression test failure when the OS user is not gpadmin.\\n- Fixed the compiler warning in appendonlyblockdirectory.c.\\n- Fixed missing reloptions in partition roots created using Cloudberry syntax.\\n- Fixed the crash when calling get_ao_compression_ratio on HEAP tables.\\n- Fixed incorrect sortOp and eqOp values generated by IsCorrelatedEqualityOpExpr.\\n- Fixed the dependency bug involving minirepro and materialized views.\\n- Fixed recursion handling in ALTER TABLE ... ENABLE/DISABLE TRIGGER.\\n- Fixed SPE plans to display Partitions selected: 1 (out of 5).\\n- Fixed incorrect hash-key generation for Redistribute Motion when creating paths for multi-DQA expressions.\\n- Removed gp_enable_sort_distinct and noduplicates optimizations.\\n- Fixed gpinitsystem Behave tests that use environment variables.\\n- Fixed false alarms in gpcheckcat for pg_default_acl.\\n- Fixed gpinitsystem failure with custom locale settings.\\n- Fixed a panic in the greenplum_fdw test.\\n- Fixed the failure in bitmap index null-array condition.\\n- Fixed the compilation warning in gram.y.\\n- Fixed multiple issues related to DistributedTransaction handling.\\n- Fixed compile-time warnings in pg_basebackup code.\\n- Fixed gplogfilter to correctly generate CSV output.\\n- Fixed the assert in the OpExecutor node.\\n- Fixed improper copying of group statistics in ORCA.\\n- Fixed error reporting after ioctl() call in pg_upgrade --clone mode.\\n- Fixed replay of CREATE DATABASE records on standby.\\n- Fixed a minor memory leak in pg_dump.\\n- Fixed parallel restore of foreign keys to partitioned tables.\\n- Fixed the issue where the pg_appendonly entry was not removed during AO-to-HEAP table conversion.\\n- Fixed assertion failure and segmentation fault in the backup code.\\n- Fixed fallback behavior for non-default collations.\\n- Fixed the subtransaction test for Python 3.10.\\n- Fixed Windows client compilation of libpgcommon.\\n- Fixed compiler warnings introduced by the Dynamic Scan commit.\\n- Fixed the issue where CREATE OR REPLACE TRANSFORM failed.\\n- Fixed compiler warnings for non-assert builds.\\n- Fixed lock assertions in dshash.c.\\n- Fixed \\\\watch interaction with libedit on C."},{"id":"announce-apache-cloudberry-2.0.0","metadata":{"permalink":"/blog/announce-apache-cloudberry-2.0.0","source":"@site/blog/2025-08-27-announce-apache-cloudberry-2.0.0.md","title":"Apache Cloudberry (Incubating) 2.0.0 Released","description":"Apache Cloudberry 2.0.0 is the first official release under the Apache Software Foundation.","date":"2025-08-27T00:00:00.000Z","formattedDate":"August 27, 2025","tags":[{"label":"Release","permalink":"/blog/tags/release"}],"readingTime":1.785,"hasTruncateMarker":false,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"announce-apache-cloudberry-2.0.0","title":"Apache Cloudberry (Incubating) 2.0.0 Released","description":"Apache Cloudberry 2.0.0 is the first official release under the Apache Software Foundation.","authors":["asfcloudberry"],"tags":["Release"],"image":"/img/blog/apache-cloudberry-2.0.0-release.png"},"unlisted":false,"prevItem":{"title":"What\'s New in Apache Cloudberry 2.0.0","permalink":"/blog/whats-new-in-apache-cloudberry-2.0.0"},"nextItem":{"title":"Apache Cloudberry Incubation Report - August 2025","permalink":"/blog/apache-cloudberry-incubation-report-202508"}},"content":":::note\\nSee the official announcement on the [Apache Cloudberry Dev mailing list](https://lists.apache.org/thread/8vpsybdqzhhk31vd8gfow38f14z7y40m).\\n:::\\n\\nThe Apache Cloudberry (Incubating) community is pleased to announce the release of Apache Cloudberry (Incubating) version 2.0.0, the project\u2019s first official release under the Apache Software Foundation.\\n\\nApache Cloudberry (Incubating) is a Massively Parallel Processing (MPP) database for large-scale data analytics, derived from PostgreSQL and the last open-source version of Greenplum Database. It is designed to support both on-premise and cloud deployments, providing a scalable foundation for data warehousing and advanced analytics.\\n\\nWe\u2019d like to express our gratitude to all contributors to this release, as well as to the mentors and the Apache Incubator community for their invaluable support. This milestone reflects a collaborative effort to meet ASF release requirements and establish Cloudberry as an open and community-driven project.\\n\\n## Release highlights\\n\\n- ASF-compliant licensing and NOTICE/DISCLAIMER updates\\n- Removal of binary artifacts from the source release\\n- Comprehensive source code header alignment with ASF standards\\n- Improved build process for Python and C++ components\\n- Cleaned NOTICE file and refined dependency attributions\\n\\n## Download\\n\\n- Download the release: https://cloudberry.apache.org/releases\\n- Changelog for 2.0.0: https://cloudberry.apache.org/releases/2.0.0-incubating\\n- For documentation, visit: https://cloudberry.apache.org/docs/\\n\\n## Contributors team\\n\\n> @weinan003, @fanfuxiaoran, @gfphoenix78, @avamingli, @zhangwenchao-123, @reshke, @jiaqizho, @gongxun0928, @zhangyue-hashdata, @roseduan, @leborchuk, @foreyes, @edespino, @yihong0618, @tuhaihe, @MisterRaindrop, @HuSen8891, @songdongxiaoa2, @robozmey, @Mulily0513, @tenderwg, @chipitsine, @Tao-Ma, @x4m, @hyongtao-db, @yjhjstz\\n\\n## Join us\\n\\nWe are eager to expand our community and extend an invitation to new contributors. We genuinely welcome the opportunity to collaborate with individuals who share our passion and expertise.\\n\\n- Website: https://cloudberry.apache.org\\n- Repository: https://github.com/apache/cloudberry\\n- Discussions: https://github.com/apache/cloudberry/discussions\\n- Issue tracker: https://github.com/apache/cloudberry/issues\\n- Mailing list: https://lists.apache.org/list.html?dev@cloudberry.apache.org\\n- Slack channel: https://inviter.co/apache-cloudberry\\n\\n\\n:::note\\nDisclaimer:\\nApache Cloudberry is an effort undergoing incubation at the Apache Software Foundation (ASF), sponsored by the Apache Incubator PMC. Incubation is required of all newly accepted projects until a review by the Incubator PMC demonstrates that the project has met the ASF\u2019s requirements for community and process. While incubation status is not necessarily a reflection of the project\u2019s stability or readiness for production, it does indicate that the project is working towards compliance with ASF processes and governance.\\n:::"},{"id":"apache-cloudberry-incubation-report-202508","metadata":{"permalink":"/blog/apache-cloudberry-incubation-report-202508","source":"@site/blog/2025-08-05-apache-cloudberry-incubation-report.md","title":"Apache Cloudberry Incubation Report - August 2025","description":"We\u2019re making steady progress to grow!","date":"2025-08-05T00:00:00.000Z","formattedDate":"August 5, 2025","tags":[{"label":"Incubation","permalink":"/blog/tags/incubation"}],"readingTime":2.78,"hasTruncateMarker":true,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"apache-cloudberry-incubation-report-202508","title":"Apache Cloudberry Incubation Report - August 2025","description":"We\u2019re making steady progress to grow!","authors":["asfcloudberry"],"tags":["Incubation"],"image":"/img/blog/apache-cloudberry-incubation-report.png"},"unlisted":false,"prevItem":{"title":"Apache Cloudberry (Incubating) 2.0.0 Released","permalink":"/blog/announce-apache-cloudberry-2.0.0"},"nextItem":{"title":"Apache Cloudberry @ Community Over Code Asia 2025 - Explore Sessions and Visit Our Booth!","permalink":"/blog/apache-cloudberry-at-community-over-code-asia-2025"}},"content":":::note\\n\\nThis Cloudberry incubation report summarizes our major progress during May and July 2025. It is adapted from the [Apache Incubator Report August 2025](https://cwiki.apache.org/confluence/display/INCUBATOR/August2025), with some modifications for readability.\\n\\n:::\\n\\n\x3c!-- truncate --\x3e\\n\\n## Cloudberry \\n\\nCloudberry is an advanced and mature open-source Massively Parallel Processing (MPP) database, derived from the open-source version of Pivotal Greenplum Database\xae\ufe0f but built on a more modern PostgreSQL 14 kernel, whereas Greenplum is based on PostgreSQL 12. This upgrade brings enhanced enterprise capabilities, making Cloudberry well-suited for data warehousing, large-scale analytics, and AI/ML workloads.\\n\\nCloudberry has been incubating since 2024-10-11.\\n\\n### Three most important unfinished issues to address before graduating:\\n\\n  1. Publish the first Apache release following ASF release processes.\\n  2. Grow the contributor and community to ensure long-term sustainability.\\n\\n### How has the community developed since the last report?\\n\\n  - Mailing list Activity: 221 new emails on the Dev mailing list since the last report, covering technical and Apache-related discussions.\\n  - Slack Activity: 15 new threads in `general` channel, 5 new members since last report.\\n  - GitHub Discussions: 16 new threads since last report.\\n  - New Committers:\\n    - May 21, 2025 - Wenchao Zhang (zhangwenchao-123)\\n    - July 9, 2025 - Xun Gong (gongxun0928)\\n  - Events:\\n    - Community Over Code Asia 2025: six presentations on Cloudberry at this conference, covering AI, Data Warehouse, OLAP and Incubator tracks. There was one Cloudberry booth.\\n    - HOW2025: PostgreSQL & IvorySQL Eco Conference in Jinan, China: PPMC members Dianjin Wang and Max Yang attended this conference and introduced Apache Cloudberry to the audience.\\n    - 10-minute T3D session on Apache Cloudberry from PPMC Member Tushar Pednekar with the host Joshua Drake: https://youtu.be/0mPCoEXG0XU\\n    - PPMC member Tushar Pednekar had a presentation on Cloudberry + Flink at Flink Forward Asia, Singapore 2025: https://www.youtube.com/watch?v=K9d572vOvNY\\n    - Presentation recording available at https://www.youtube.com/watch?v=lMYqOoE4p5A, by contributor @Leonid Borchuk and PPMC Member @Kirill Reshke at the sql-ninja conference.\\n\\n### How has the project developed since the last report?\\n\\n  - Compliance with ASF policy:\\n    - Renamed `greenplum_path` to `cloudberry-env.sh` for better compliance with ASF rules.\\n    - Updated Apache RAT license metadata for release.\\n    - Changed PAX\'s cpp-stub from submodule to subdir to avoid introducing binary files.\\n    - Changed Python modules for gpMgmt from bundling their source tarballs to downloading them during the build process via `pip3 install`.\\n  - Working on the first Apache Cloudberry (Incubating) 2.0.0 release:\\n    - Already had RC1 & RC2 rounds and fixed some license issues, will have an RC3 round for the dev vote and Apache Incubator vote.\\n  - PostgreSQL Kernel upgrade: the community developer has started the kernel upgrade work from PG 14.4 to PG 16.6.\\n  - 130 new commits to main branch since the last report, focusing on performance improvements, bug fixes and new features.\\n  - Ecosystem:\\n    - Apache SeaTunnel added official connector support for Apache Cloudberry in its latest 2.3.11 release (See https://s.apache.org/baj30).\\n    - Flink JDBC Connector v3.3.0+ now supports Cloudberry via PR https://s.apache.org/jt29r\\n  - Our GitHub main repo has reached 1k+ GitHub stars!\\n\\n### How would you assess the podling\'s maturity?\\n\\n  - [ ] Initial setup\\n  - [X] Working towards first release\\n  - [X] Community building\\n  - [ ] Nearing graduation\\n  - [ ] Other:\\n\\n### Date of last release:\\n\\n  N/A\\n\\n### When were the last committers or PPMC members elected?\\n\\n  - May 21, 2025 - Wenchao Zhang (zhangwenchao-123)\\n  - July 9, 2025 - Xun Gong (gongxun0928)"},{"id":"apache-cloudberry-at-community-over-code-asia-2025","metadata":{"permalink":"/blog/apache-cloudberry-at-community-over-code-asia-2025","source":"@site/blog/2025-07-09-apache-cloudberry-at-community-over-code-asia-2025.md","title":"Apache Cloudberry @ Community Over Code Asia 2025 - Explore Sessions and Visit Our Booth!","description":"Community Over Code Asia 2025 is coming!","date":"2025-07-09T00:00:00.000Z","formattedDate":"July 9, 2025","tags":[{"label":"Event","permalink":"/blog/tags/event"}],"readingTime":6.095,"hasTruncateMarker":false,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"apache-cloudberry-at-community-over-code-asia-2025","title":"Apache Cloudberry @ Community Over Code Asia 2025 - Explore Sessions and Visit Our Booth!","description":"Community Over Code Asia 2025 is coming!","authors":["asfcloudberry"],"tags":["Event"],"image":"/img/blog/202507-coc-asia.png"},"unlisted":false,"prevItem":{"title":"Apache Cloudberry Incubation Report - August 2025","permalink":"/blog/apache-cloudberry-incubation-report-202508"},"nextItem":{"title":"Goodbye `greenplum_path.sh`, Hello `cloudberry-env.sh`: A Phased Transition Plan","permalink":"/blog/from-greenplum-path.sh-to-cloudberry-env.sh"}},"content":"![community over code asia 2025](/img/blog/coc-asia-logo-dark.png)\\n\\nWe\u2019re thrilled to welcome you to [Community Over Code Asia 2025](https://asia.communityovercode.org) (previously known as ApacheCon Asia) - the premier open-source event in Asia, hosted by the Apache Software Foundation. Taking place in Beijing from July 25\u201327, 2025, this in-person gathering is your chance to dive into the latest innovations, learn from domain experts, and connect with the global open-source community.\\n\\nApache Cloudberry will be featured across six exciting sessions, covering everything from architecture deep dives and AI integration to real-world use cases and roadmap insights. Whether you\u2019re a developer, data engineer, database specialist, or decision-maker, there\u2019s something for you.\\n\\n## Featured sessions\\n\\nLet\u2019s take a look at the featured Apache Cloudberry sessions, ranging from project introductions and deep technical dives to practical solutions and strategic insights.\\n\\n#### SeaTunnel Architecture Analysis and Cloudberry Integration Practice\\n\\nHongyu Chen, SeaTunnel Contributor and Data Integration R&D Engineer at NetEase\\n\\n    > In this session, we will explore Apache SeaTunnel, a high-performance distributed data integration platform designed for seamless synchronization of massive datasets across heterogeneous sources. Attendees will gain insights into SeaTunnel\u2019s core architecture, including its modular plugin system, unified abstractions leveraging Spark and Flink, and its evolution from V1 to V2 with enhanced scalability and engine-agnostic design. We will delve into advanced features such as dynamic sharding strategies, data sampling techniques, and optimized handling of string-based partitioning for efficient data distribution.\\n    >\\n    > The session will also showcase a practical integration case with Cloudberry, demonstrating how SeaTunnel\u2019s JDBC-based connector simplifies bidirectional data workflows while highlighting performance considerations. Finally, we\u2019ll discuss future optimizations, including plans to leverage Cloudberry\u2019s parallel processing via the gpfdist protocol for large-scale data migration. This talk is ideal for data engineers and architects seeking to streamline data integration workflows, break down silos, and harness the full potential of modern data ecosystems.\\n\\nIdeal for data engineers interested in cross-platform data pipelines and performance tuning.\\n\\n\ud83e\udef1 Session details: https://asia.communityovercode.org/sessions/dataops-915377.html\\n\\n#### From Proposal to Progress: Lessons Learned from Incubating Apache Cloudberry\\n\\nDianjin Wang, PPMC Member of Apache Cloudberry, ALC Beijing Member, Track Chair of ApacheCon Asia 2021-2025, Head of Open Source at HashData\\n\\n    > Apache Cloudberry, a massively parallel processing (MPP) database based on Greenplum, entered the Apache Incubator with the vision of bringing analytical power to the open-source community. As one of the initiators and ongoing contributors to the project, I\u2019ve had the opportunity to closely experience every stage of the incubation journey \u2014 from drafting the proposal and forming the PPMC to announcing and marketing promotion, to cleaning up the source code, and building community momentum.\\n    >\\n    > In this talk, I will share firsthand insights into what it takes to navigate the Apache Incubator process effectively. I\u2019ll highlight the challenges we faced, how we built a diverse and active community, ensured compliance with Apache\u2019s governance and IP guidelines, and balanced open-source development with commercial interests. This session aims to offer practical guidance for new and prospective incubator projects, mentors, and contributors interested in sustaining healthy open-source ecosystems under the Apache Way.\\n\\nA must-attend for new incubator projects, mentors, or anyone curious about open-source sustainability.\\n\\n\ud83e\udef1 Session details: https://asia.communityovercode.org/sessions/incubator-906736.html\\n\\n#### Dive into Vectorized Execution for Apache Cloudberry: Design, Challenges, and Performance Gains\\n\\nZhang Yue, Software Engineer at HashData\\n\\n    > As analytical workloads grow in both scale and complexity, the demand for high-performance data processing engines continues to rise. While MPP architectures are effective at scaling out performance across hardware, databases built on PostgreSQL \u2014 such as Greenplum and Apache Cloudberry \u2014 face limitations due to PostgreSQL\u2019s execution engine.\\n    >\\n    > To overcome these constraints, we introduce a vectorized execution engine for Apache Cloudberry, which is designed to unlock greater efficiency through batch processing and low-level instruction optimizations. In this session, we will take a deep dive into the design and implementation of Cloudberry\u2019s vectorized engine solution, outline the key engineering efforts behind it, and share insights from real-world use cases\u2014including performance benchmarks, bottlenecks we encountered, and future directions for further optimization.\\n\\nJoin this talk if you\u2019re interested in performance engineering or modern MPP execution models.\\n\\n\ud83e\udef1 Session details: https://asia.communityovercode.org/sessions/olap-914602.html\\n\\n#### From Data to AI: Building a Unified Analytics Platform with Apache Cloudberry\\n\\nChuanxin Bian, Data & AI Engineer at HashData\\n\\n    > Enterprises today struggle to harness AI\u2019s full potential due to fragmented data systems, inefficient pipelines, and silos between analytics and machine learning. Apache Cloudberry, an open-source MPP data warehouse, redefines this paradigm by deeply integrating data processing with AI - eliminating barriers and accelerating innovation. In this session, we\u2019ll demonstrate how Cloudberry enables:\\n    > \\n    > - Unified Execution \u2013 Run native AI/ML models (e.g., PyTorch, Scikit-learn) directly on warehouse data.\\n    > - Multi-Modal Analytics \u2013 Process structured and unstructured data (PDFs, images, and other documents) in a unified framework.\\n    > - Smart Data Applications \u2013 Build RAG-enhanced QA, ChatBI, and multimodal search. \\n    >\\n    > You can learn how to converge data and intelligence into one platform, reducing complexity while scaling AI workloads in this session.\\n\\nIf you\u2019re building AI workflows on top of analytics infrastructure, don\u2019t miss this session.\\n\\n\ud83e\udef1 Session details: https://asia.communityovercode.org/sessions/ai-915004.html\\n\\n#### Building a Unified Lakehouse Solution with Apache Cloudberry\\n\\nRose Duan, Apache Cloudberry contributor\\n\\n    > Data warehouses excel at fast analytics, while data lakes focus on scalable storage and flexible data management. The lakehouse architecture aims to combine the best of both\u2014seamlessly integrating data across lakes and warehouses for efficient analysis and unified governance.\\n    >\\n    > As a next-generation open-source MPP database, Apache Cloudberry extends its technical boundaries to build an open lakehouse solution. This talk introduces Cloudberry\u2019s key capabilities in enabling a unified lakehouse architecture:\\n    > \\n    > 1. Accelerated lake queries on Parquet/ORC without data movement\\n    > 2. Unified data gateway for querying and writing across heterogeneous sources\\n    > 3. Integrated data processing and sync pipeline, enabling end-to-end flow from ingestion to analytics\\n    > 4. Open metadata and storage formats for easier ecosystem integration and reduced migration cost\\n\\nPerfect for architects and data platform teams building open, scalable analytics stacks.\\n\\n\ud83e\udef1 Session details: https://asia.communityovercode.org/sessions/datalake-915987.html\\n\\n#### Introduction to Apache Cloudberry: Evolution, Key Features, and Roadmap\\n\\nMax Yang, Apache Cloudberry PPMC Member, Tech VP of HashData\\n\\n    > Apache Cloudberry is an advanced and mature open-source MPP database, derived from the open-source version of the Pivotal Greenplum Database\xae but built on a more modern PostgreSQL kernel and with more advanced enterprise capabilities. Cloudberry can serve as a data warehouse and can also be used for large-scale analytics and AI/ML workloads. \\n    >\\n    > In this session, we\u2019ll explore the origin of the project, its journey into the Apache Incubator, and how it differentiates itself from other analytical databases. We will introduce Cloudberry\u2019s core features, architectural highlights, and share its future roadmap. This session will also provide a brief comparison with other data warehouse systems, helping the audience understand where Apache Cloudberry stands in the ecosystem and what\u2019s coming next.\\n\\nA great entry point for understanding Cloudberry\u2019s position in the data warehouse landscape.\\n\\n\ud83e\udef1 Session details: https://asia.communityovercode.org/sessions/datalake-915155.html\\n\\n## How to participate\\n\\nReady to join? [Register](https://asia.communityovercode.org/#register) now to attend Community Over Code Asia 2025 in person. We look forward to seeing you in Beijing!\\n\\n## Visit the Cloudberry Booth!\\n\\nThe Apache Cloudberry community will be onsite with a dedicated booth. Drop by to meet the team, ask questions, check out live demos, and grab some awesome Cloudberry swag!"},{"id":"from-greenplum-path.sh-to-cloudberry-env.sh","metadata":{"permalink":"/blog/from-greenplum-path.sh-to-cloudberry-env.sh","source":"@site/blog/2025-07-02-from-greenplum_path.sh-to-cloudberry_env.sh.md","title":"Goodbye `greenplum_path.sh`, Hello `cloudberry-env.sh`: A Phased Transition Plan","description":"Renaming legacy scripts such as greenplum_path.sh to cloudberry-env.sh.","date":"2025-07-02T00:00:00.000Z","formattedDate":"July 2, 2025","tags":[{"label":"Announcement","permalink":"/blog/tags/announcement"}],"readingTime":2.91,"hasTruncateMarker":false,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"from-greenplum-path.sh-to-cloudberry-env.sh","title":"Goodbye `greenplum_path.sh`, Hello `cloudberry-env.sh`: A Phased Transition Plan","description":"Renaming legacy scripts such as greenplum_path.sh to cloudberry-env.sh.","authors":["asfcloudberry"],"tags":["Announcement"],"image":"/img/blog/202507-notice-cloudberry-env.png"},"unlisted":false,"prevItem":{"title":"Apache Cloudberry @ Community Over Code Asia 2025 - Explore Sessions and Visit Our Booth!","permalink":"/blog/apache-cloudberry-at-community-over-code-asia-2025"},"nextItem":{"title":"Apache Cloudberry 2.0 Preview: Key Features and Improvements Ahead","permalink":"/blog/apache-cloudberry-2.0-preview-key-features-and-improvements-ahead"}},"content":"To the Apache Cloudberry Community,\\n\\nThis post outlines our plan to rename legacy user-facing scripts such as `greenplum_path.sh`, aligning them with Apache Cloudberry\u2019s official brand identity and complying with ASF trademark policy. This will be a two-step process designed to be transparent and minimize disruption for our users.\\n\\n## Background: Why This Change is Necessary\\n\\nAs Apache Cloudberry (Incubating) matures, establishing a clear and independent brand identity is essential. While our project originated from Greenplum, it is now independently governed under the ASF Incubator, with a distinct development roadmap.\\n\\nThe \\"Greenplum\\" name is a registered trademark owned by Broadcom Inc.. To comply with ASF policies and avoid potential trademark confusion, the PPMC reached a consensus through the discussion that took place on the Dev@ mailing list and GitHub issues to rename legacy user-facing scripts that use the `Greenplum` name term.\\n\\n## A Phased Approach to the Transition\\n\\nTo manage this transition smoothly, we will implement the changes in two phases:\\n\\n### Phase 1: Non-Breaking Notice (Release 2.0)\\n\\nThe first step has been implemented in Pull Request [#1189](https://github.com/apache/cloudberry/pull/1189) and will be included in the upcoming Apache Cloudberry 2.0 release.\\n\\n- **What\'s Changing**: When you run `source greenplum_path.sh`, you will see a notice clarifying Apache Cloudberry\u2019s independence from Broadcom\u2019s Greenplum, like the following output:\\n\\n    ```bash\\n    [gpadmin@cloudberry]$ source /usr/local/cloudberry-db/greenplum_path.sh\\n\\n    # --------------------------------------------------------------------\\n    # NOTICE from the Apache Cloudberry PPMC\\n    # --------------------------------------------------------------------\\n    # This file uses the term \'greenplum\' to maintain compatibility with\\n    # earlier versions of Apache Cloudberry, which was originally called\\n    # Greenplum. This usage does not refer to VMware Tanzu Greenplum,\\n    # nor does it imply that Apache Cloudberry (Incubating) is affiliated\\n    # with, endorsed by, or sponsored by Broadcom Inc.\\n    #\\n    # This file will be renamed in a future Apache Cloudberry release to\\n    # ensure compliance with Apache Software Foundation guidelines.\\n    # We will announce the change on the project mailing list and website.\\n    #\\n    # See: https://lists.apache.org/thread/b8o974mnnqk6zpy86dgll2pgqcvqgnwm\\n    # --------------------------------------------------------------------\\n    ```\\n\\n- **Impact**: This is a **non-breaking change**. Your scripts and workflows will continue to function as before. This step offers immediate brand clarification and serves as advance notice of the upcoming rename.\\n\\n### Phase 2: Full Rename (Targeted for Release 2.1)\\n\\nThe second step will complete the brand alignment.\\n\\n* **What\'s Changing**: We plan to formally rename `greenplum_path.sh` to `cloudberry-env.sh`. This effort may also include a broader review of related configuration scripts and internal naming for consistency.\\n* **Impact**: This will be a **breaking change**. You need to run the command `source cloudberry-env.sh` instead of `source greenplum_path.sh`. The change will be documented in the release notes, along with an optional alias method in the documentation, like: \\n\\n    ```bash \\n    sudo ln -s /usr/local/cloudberry-db/cloudberry-env.sh /usr/local/cloudberry-db/greenplum_path.sh\\n    ```\\n\\n### What This Means for You\\n\\n- **For the 2.0 Release**: No action is required. Simply be aware that the notice will now appear when setting up your environment.\\n- **For the 2.1 Release**: Plan to update your scripts to use the new `cloudberry-env.sh` file.\\n\\n## Moving Forward\\n\\nThis initiative lays a stronger foundation for the project\'s future as we continue our journey toward becoming a Top-Level Project. We thank everyone who participated in the discussion and the ASF legal team for the valuable inputs and advice.\\n\\nThank you for your support and understanding.\\n\\n## Related Discussion\\n\\n- GitHub PR: https://github.com/apache/cloudberry/pull/1189\\n- Mailing list thread: https://lists.apache.org/thread/b8o974mnnqk6zpy86dgll2pgqcvqgnwm\\n\\n## Join Us\\n\\n- Visit the website: [https://cloudberry.apache.org](https://cloudberry.apache.org)\\n- Follow us on GitHub: [https://github.com/apache/cloudberry](https://github.com/apache/cloudberry)\\n- Join Slack workspace: [https://apache-cloudberry.slack.com](https://apache-cloudberry.slack.com)\\n- Dev mailing list: to subscribe and check the archives, please visit [here](/community/mailing-lists)"},{"id":"apache-cloudberry-2.0-preview-key-features-and-improvements-ahead","metadata":{"permalink":"/blog/apache-cloudberry-2.0-preview-key-features-and-improvements-ahead","source":"@site/blog/2025-06-20-apache-cloudberry-2.0-preview.md","title":"Apache Cloudberry 2.0 Preview: Key Features and Improvements Ahead","description":"Key highlights of Apache Cloudberry 2.0","date":"2025-06-20T00:00:00.000Z","formattedDate":"June 20, 2025","tags":[{"label":"Release","permalink":"/blog/tags/release"}],"readingTime":4.215,"hasTruncateMarker":false,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"apache-cloudberry-2.0-preview-key-features-and-improvements-ahead","title":"Apache Cloudberry 2.0 Preview: Key Features and Improvements Ahead","description":"Key highlights of Apache Cloudberry 2.0","authors":["asfcloudberry"],"tags":["Release"],"image":"/img/blog/202506-cloudberry2.0.png"},"unlisted":false,"prevItem":{"title":"Goodbye `greenplum_path.sh`, Hello `cloudberry-env.sh`: A Phased Transition Plan","permalink":"/blog/from-greenplum-path.sh-to-cloudberry-env.sh"},"nextItem":{"title":"Apache Cloudberry Incubation Report - May 2025","permalink":"/blog/apache-cloudberry-incubation-report-202505"}},"content":"The next major release of Apache Cloudberry (Incubating)\u2014version 2.0\u2014is just around the corner. As the project\u2019s first Apache release since joining the Apache Incubator, Cloudberry 2.0 brings a host of new features, performance enhancements, and compliance improvements. While the official release is still in progress, we\u2019d like to share a preview of the most exciting changes and innovations you can expect. This overview highlights the key updates and sets the stage for the upcoming launch.\\n\\n## Key Highlights of Apache Cloudberry 2.0\\n\\n### Codebase Cleanup\\n\\nOne of the major efforts in this release was cleaning up the code repository to remove outdated and unused files. This includes legacy components such as Concourse CI configurations (`concourse/*`), `hd-ci/*`, legacy deployment directories (e.g., Vagrant and Kubernetes setups), and redundant artifacts like PyGreSQL-related files. This cleanup streamlines the codebase, making it easier for contributors to navigate and focus on meaningful development.\\n\\n### Brand Refresh\\n\\nAs part of the transition to the Apache Incubator, we\u2019ve unified branding across the project source code and website. References to legacy names like \\"Cloudberry Database\\" and \\"CloudberryDB\\" have been replaced with `Apache Cloudberry` or simply `Cloudberry`. This ensures consistency and aligns the project with Apache\u2019s branding guidelines.\\n\\n### Compliance Improvements\\n\\nTo meet Apache\u2019s licensing and compliance standards, we\u2019ve added the standard Apache License headers to all relevant newly created files by the Cloudberry community, replaced incompatible tarballs like Pylint (GPL-licensed) with Ruff (MIT-licensed), and ensured the codebase passes Apache RAT validation. \\n\\nWe\u2019ve reworded the NOTICE, LICENSE, DISCLAIMER, COPYRIGHT, and SECURITY files to reflect the new Apache Cloudberry branding and compliance requirements. All submodules and components\u2019 licenses are listed in the top-level `licenses` directory.\\n\\nOur PPMC members and committers have all signed the ICLA (Individual Contributor License Agreement) files and the Cloudberry donation corporation also signed the Software Grant Agreement (SGA) files and and has been filed with the Apache Software Foundation.\\n\\nThese changes make Cloudberry fully compliant with Apache\u2019s open-source policies, paving the way for a smooth release process.\\n\\n### Cherry-Picked Enhancements from archived Greenplum\\n\\nApache Cloudberry 2.0 incorporates hundreds of commits cherry-picked from the archived Greenplum repository. These include critical bug fixes, performance improvements, and enhancements to the ORCA query optimizer and other components. While some changes outside Cloudberry\u2019s roadmap were deprioritized, the codebase is now largely aligned with Greenplum, offering a solid foundation for future development. Community contributors are welcome to pick up tasks related to these deprioritized changes. See the [proposal](https://github.com/apache/cloudberry/discussions/675) for more details.\\n\\n### New Features and Enhancements\\n\\nThis release introduces new features and enhancements that expand Cloudberry\u2019s capabilities compared to the previous Cloudberry 1.6 release:\\n\\n* Dynamic Tables: Automatically refresh query results based on base tables, external tables, or materialized views\u2014ideal for building live analytical dashboards. See the [doc](https://cloudberry.apache.org/docs/next/performance/use-dynamic-tables) for more details.\\n* PAX: Introduces a hybrid row-column storage model that improves cache efficiency and supports both object and local file systems. See the [doc](https://cloudberry.apache.org/docs/next/operate-with-data/pax-table-format) for more details.\\n* And More: Cloudberry 2.0 brings extensive enhancements across query optimization, the ORCA optimizer, transaction management, storage, data handling, resource managment, and tools. Full details will be available in the official 2.0 release notes.\\n\\n### CICD Process\\n\\nSince entering the Apache Incubator, a strong CI/CD pipeline has been established. This pipeline covers all the core tests and checks to ensure the quality of the codebase. At the same time, it can support parallel tests to speed up the CI/CD process, and output the detailed test result parsing and reporting, etc. \\n\\nAs an Apache Incubator project, Apache Cloudberry 2.0 follows the Apache Software Foundation\u2019s release process, including community discussions, voting, and compliance checks. This ensures the release meets the standards of quality and transparency.\\n\\n### Security Enhancements\\n\\nSecurity has been a top priority for Apache Cloudberry 2.0. We\u2019ve introduced Coverity Scan and SonarQube for automated weekly code analysis, ensuring the codebase is robust and secure. \\n\\nAdditionally, we\u2019ve addressed critical vulnerabilities, including PostgreSQL CVE-2025-1049 fixes, and upgraded dependencies such as `PyYAML` to patch known issues. These measures reinforce Cloudberry\u2019s commitment to providing a secure and reliable database platform.\\n\\n### Website and Docs updates\\n\\nThe website and documentation have been updated to reflect the new branding and features. The website now includes a new design, updated content, and better navigation. The documentation has been updated to reflect the new features and changes in the codebase.\\n\\n## Looking Ahead\\n\\nAs an Apache Incubator project, Cloudberry 2.0 follows the ASF\u2019s rigorous release process, including open discussion, voting, and compliance checks. This ensures transparency, quality, and community trust.\\n\\nWith a cleaner codebase, enhanced security, and exciting new features and enhancements, Apache Cloudberry 2.0 will be a major milestone that sets the stage for future innovation. We invite the community to join us in shaping the future of Apache Cloudberry by contributing, testing, and sharing feedback.\\n\\nStay tuned for the official 2.0 release announcement! Thank you for being part of the Apache Cloudberry journey!\\n\\n## Join Us\\n\\n- Visit the website: [https://cloudberry.apache.org](https://cloudberry.apache.org)\\n- Follow us on GitHub: [https://github.com/apache/cloudberry](https://github.com/apache/cloudberry)\\n- Join Slack workspace: [https://apache-cloudberry.slack.com](https://apache-cloudberry.slack.com)\\n- Dev mailing list: to subscribe and check the archives, please visit [here](/community/mailing-lists)"},{"id":"apache-cloudberry-incubation-report-202505","metadata":{"permalink":"/blog/apache-cloudberry-incubation-report-202505","source":"@site/blog/2025-05-23-apache-cloudberry-incubation-report.md","title":"Apache Cloudberry Incubation Report - May 2025","description":"We\u2019re making steady progress to grow!","date":"2025-05-23T00:00:00.000Z","formattedDate":"May 23, 2025","tags":[{"label":"Incubation","permalink":"/blog/tags/incubation"}],"readingTime":3.065,"hasTruncateMarker":true,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"apache-cloudberry-incubation-report-202505","title":"Apache Cloudberry Incubation Report - May 2025","description":"We\u2019re making steady progress to grow!","authors":["asfcloudberry"],"tags":["Incubation"],"image":"/img/blog/apache-cloudberry-incubation-report.png"},"unlisted":false,"prevItem":{"title":"Apache Cloudberry 2.0 Preview: Key Features and Improvements Ahead","permalink":"/blog/apache-cloudberry-2.0-preview-key-features-and-improvements-ahead"},"nextItem":{"title":"Welcoming Wenchao Zhang as a New Apache Cloudberry Committer","permalink":"/blog/welcoming-wenchaozhang-as-a-new-apache-cloudberry-committer"}},"content":":::note\\n\\nThis Cloudberry incubation report summarizes our major progress during March and April 2025. It is adapted from the [Apache Incubator Report May 2025](https://cwiki.apache.org/confluence/display/INCUBATOR/May2025#cloudberry), with some modifications for readability.\\n\\n:::\\n\\n\x3c!-- truncate --\x3e\\n\\n## Cloudberry \\n\\nCloudberry is an advanced and mature open-source Massively Parallel Processing (MPP) database, derived from the open-source version of Pivotal Greenplum Database\xae\ufe0f but built on a more modern PostgreSQL 14 kernel, whereas Greenplum is based on PostgreSQL 12. This upgrade brings enhanced enterprise capabilities, making Cloudberry well-suited for data warehousing, large-scale analytics, and AI/ML workloads.\\n\\nCloudberry has been incubating since 2024-10-11\\n\\n### Three most important unfinished issues to address before graduating:\\n\\n  1. Complete the source code cleanup to ensure ASF compliance.\\n  2. Publish the first Apache release following ASF release processes.\\n  3. Grow the contributor and community to ensure long-term sustainability.\\n\\n### How has the community developed since the last report?\\n\\n  - Mailing list Activity: 59 messages and 92 messages on the Dev mailing list in March and April 2025, covering technical and Apache-related\\n  discussions.\\n  - Slack Activity: 16 new threads in `general` channel, 27 new members since last report.\\n  - GitHub Discussions: 4 new threads in March and 7 new threads in April.\\n  - New Committer: welcomed our first committer since joining the incubator.\\n    - Mar 19, 2025 - Xiong Tong\\n  - Events:\\n    - Join OSPP 2025 to attract university students to join the open-source development\\n    - A Cloudberry Meetup hosted by HashData in Hangzhou attracted 30~ attendees.\\n    - The contributor @Leonid Borchuk and PPMC Member @Kirill Reshke presented their talks on Cloudberry at the sql-ninja conference in Moscow\\n      on 03/22, 2025.\\n    - PPMC member Shine Zhang presented \\"From Greenplum to Apache Cloudberry\\" at Postgres Conference 2025, Orlando / United States, March 20, 2025\\n    - 6+ Cloudberry proposals are submitted to CommunityOverCode NA/Asia 2025 (still in review and waiting for the final approval).\\n    - Create website pages to guide on how to invite the new committer.\\n\\n### How has the project developed since the last report?\\n\\n  - Create the Wiki space in GitHub to organize the collective knowledge from community practices, including the release process.\\n  - Security:\\n    - Integrated two code analysis tools to enhance our code quality and identify potential issues in the development process: Coverity Scan and SonarQube Scan.\\n    - Fix the PostgreSQL security issue CVE-2025-1094.\\n  - CICD:\\n    - Working on adding the Ubuntu build and test environment support to Cloudberry\\n  - Codebase Updates:\\n    - Evolve the Cloudberry code following the Roadmap: Contributed back the row-column hybrid storage engine -PAX to the Cloudberry codebase;\\n    - Completed the first stage of cherry-picking commits from the open-source Greenplum project to Cloudberry (80%+ progress of plan).\\n    - Work for the first Apache Cloudberry (Incubating) 2.0.0 release\\n      - Pull Request management through the GitHub project: https://github.com/orgs/apache/projects/490\\n  - License-related updates: \\n    - Update the NOTICE and LICENSE files.\\n    - List the third-party licenses under the `licenses` directory.\\n    - Replace the Pylint with a license-compatible one - ruff.\\n    - Update the license headers with the Apache license header for the newly created files.\\n    - Add RAT license audit config and compliance metadata.\\n  - Brand updates: rebrand old names to the latest Apache Cloudberry brand both in the main codebase and the site source.\\n  - Cleanup the old unused files from the source code for a clearer codebase and ASF compliance (including `concourse/*`, `hd-ci/*`, `deploy/*`, and so on).\\n\\n### How would you assess the podling\'s maturity?\\n\\n  - [ ] Initial setup\\n  - [X] Working towards first release\\n  - [X] Community building\\n  - [ ] Nearing graduation\\n  - [ ] Other:\\n\\n### Date of last release:\\n\\n  N/A\\n\\n### When were the last committers or PPMC members elected?\\n\\n  - Mar 19, 2025 - Xiong Tong (committer)"},{"id":"welcoming-wenchaozhang-as-a-new-apache-cloudberry-committer","metadata":{"permalink":"/blog/welcoming-wenchaozhang-as-a-new-apache-cloudberry-committer","source":"@site/blog/2025-05-22-welcoming-wenchaozhang-as-a-new-apache-cloudberry-committer.md","title":"Welcoming Wenchao Zhang as a New Apache Cloudberry Committer","description":"Becoming a committer demonstrates a strong commitment to the community.","date":"2025-05-22T00:00:00.000Z","formattedDate":"May 22, 2025","tags":[{"label":"Announcement","permalink":"/blog/tags/announcement"}],"readingTime":0.885,"hasTruncateMarker":true,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"welcoming-wenchaozhang-as-a-new-apache-cloudberry-committer","title":"Welcoming Wenchao Zhang as a New Apache Cloudberry Committer","description":"Becoming a committer demonstrates a strong commitment to the community.","authors":["asfcloudberry"],"tags":["Announcement"],"image":"/img/blog/welcome-new-committer-blog-banner.png"},"unlisted":false,"prevItem":{"title":"Apache Cloudberry Incubation Report - May 2025","permalink":"/blog/apache-cloudberry-incubation-report-202505"},"nextItem":{"title":"Welcoming Xiong Tong as a New Apache Cloudberry Committer","permalink":"/blog/welcoming-xiongtong-as-a-new-apache-cloudberry-committer"}},"content":"![Welcoming Wenchao Zhang as a New Committer](/img/blog/202505-welcome-new-committer-wenchaozhang-banner-large.png)\\n\\nWe are thrilled to announce that Wenchao Zhang (GitHub ID: zhangwenchao-123) has officially joined the Apache Cloudberry community as a committer! The Podling Project Management Committee (PPMC) for Apache Cloudberry invited him to become a committer, and we are pleased to announce that he has accepted this invitation.\\n\\n\x3c!-- truncate --\x3e\\n\\nWenchao has made consistent and meaningful contributions to the Cloudberry project, particularly in the directory table, password profile feature, and performance issues. You can review his commit history here: [Wenchao\'s Contributions](https://github.com/apache/cloudberry/commits?author=zhangwenchao-123).\\n\\nHis technical insights, responsiveness, and collaboration with the community have made a positive impact, and we believe he is a valuable addition to the Committer team.\\n\\nBecoming a committer is a significant milestone that reflects both technical expertise and a strong commitment to the community. We are excited to see Wenchao Zhang continue to make meaningful contributions and take on greater responsibility within the project.\\n\\nPlease join us in congratulating Wenchao Zhang on this well-deserved achievement and welcoming him to his new role in the Apache Cloudberry community!"},{"id":"welcoming-xiongtong-as-a-new-apache-cloudberry-committer","metadata":{"permalink":"/blog/welcoming-xiongtong-as-a-new-apache-cloudberry-committer","source":"@site/blog/2025-03-24-welcoming-xiongtong-as-a-new-apache-cloudberry-committer.md","title":"Welcoming Xiong Tong as a New Apache Cloudberry Committer","description":"Becoming a committer is a strong commitment to the community.","date":"2025-03-24T00:00:00.000Z","formattedDate":"March 24, 2025","tags":[{"label":"Announcement","permalink":"/blog/tags/announcement"}],"readingTime":0.815,"hasTruncateMarker":true,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"welcoming-xiongtong-as-a-new-apache-cloudberry-committer","title":"Welcoming Xiong Tong as a New Apache Cloudberry Committer","description":"Becoming a committer is a strong commitment to the community.","authors":["asfcloudberry"],"tags":["Announcement"],"image":"/img/blog/welcome-new-committer-blog-banner.png"},"unlisted":false,"prevItem":{"title":"Welcoming Wenchao Zhang as a New Apache Cloudberry Committer","permalink":"/blog/welcoming-wenchaozhang-as-a-new-apache-cloudberry-committer"},"nextItem":{"title":"Cloudberry Database Enters the Apache Incubator: A New Chapter in Open-Source MPP Database for Analytics and AI","permalink":"/blog/cloudberry-database-enters-the-apache-incubator"}},"content":"![Welcoming Xiong Tong as a New Committer](/img/blog/202503-welcome-new-committer-xiongtong-banner-large.png)\\n\\nWe are thrilled to announce that Xiong Tong (GitHub ID: TomShawn) has officially joined the Apache Cloudberry community as a committer! The Podling Project Management Committee (PPMC) for Apache Cloudberry extended the invitation, and we are delighted that he has accepted this new role.\\n\\n\x3c!-- truncate --\x3e\\n\\nOver the past two years, TomShawn has made outstanding contributions to the project\'s documentation, significantly enhancing the clarity and accessibility of our resources. His dedication and commitment have played a crucial role in shaping the project\'s documentation landscape. You can explore his impactful work here: [TomShawn\'s Contributions](https://github.com/apache/cloudberry-site/commits?author=TomShawn).\\n\\nBecoming a committer is a significant milestone that reflects both technical expertise and a strong commitment to the community. We are excited to see Xiong Tong continue to make meaningful contributions and take on greater responsibilities within the project.\\n\\nPlease join us in congratulating Xiong Tong on this well-deserved achievement and welcoming him to his new role in the Apache Cloudberry community!"},{"id":"cloudberry-database-enters-the-apache-incubator","metadata":{"permalink":"/blog/cloudberry-database-enters-the-apache-incubator","source":"@site/blog/2024-11-20-cloudberry-database-enters-the-apache-incubator.md","title":"Cloudberry Database Enters the Apache Incubator: A New Chapter in Open-Source MPP Database for Analytics and AI","description":"Cloudberry is now rebranded to Apache Cloudberry\u2122\ufe0f (Incubating).","date":"2024-11-20T00:00:00.000Z","formattedDate":"November 20, 2024","tags":[{"label":"Announcement","permalink":"/blog/tags/announcement"}],"readingTime":5,"hasTruncateMarker":true,"authors":[{"name":"Apache Cloudberry","imageURL":"/img/blog/dbteam.png","key":"asfcloudberry"}],"frontMatter":{"slug":"cloudberry-database-enters-the-apache-incubator","title":"Cloudberry Database Enters the Apache Incubator: A New Chapter in Open-Source MPP Database for Analytics and AI","description":"Cloudberry is now rebranded to Apache Cloudberry\u2122\ufe0f (Incubating).","authors":["asfcloudberry"],"tags":["Announcement"],"image":"/img/blog/202411-ASF-Incubator.jpeg"},"unlisted":false,"prevItem":{"title":"Welcoming Xiong Tong as a New Apache Cloudberry Committer","permalink":"/blog/welcoming-xiongtong-as-a-new-apache-cloudberry-committer"}},"content":"On October 12th, 2024, the Cloudberry Database project was voted to enter the Apache Software Foundation Incubator[^1], marking a significant milestone for the Cloudberry project and its community. On November 5th, 2024, the Cloudberry project repositories were transferred to the Apache Software Foundation. With this transition, Cloudberry has fully joined the incubator and begun its development under the Apache umbrella. Additionally, the Cloudberry Database is now proudly rebranded to Apache Cloudberry\u2122\ufe0f (Incubating).\\n\\n![Cloudberry Database enters Apache Incubator](/img/blog/cloudberry-database-enters-apache-incubator.jpeg)\\n\\n\x3c!-- truncate --\x3e\\n\\n## What is Cloudberry\\n\\nCloudberry, created by the original developers of Greenplum Database, is an advanced and mature open-source Massively Parallel Processing (MPP) database. It evolves from the open-source version of the Pivotal Greenplum Database\xae but features a newer PostgreSQL kernel and more advanced enterprise capabilities. Cloudberry can serve as a data warehouse and can also be used for large-scale analytics and AI/ML workloads.\\n\\n![Apache Cloudberry Logo](/img/blog/apache-cloudberry-logo-color.png)\\n\\nThe Greenplum Database has been massively adopted by large numbers of small, medium, and big giant teams from different industries. It is also listed among the Top50 popular databases according to the [DB-Engines website](https://db-engines.com/en/ranking). However, with the archiving of the open-source Greenplum Database and a complete shutdown of its community, original open-source Greenplum users cannot get the security or feature updates for free anymore which results in potential challenges for their business.\\n\\nWe want to make Cloudberry the primary open-source alternative to the original Greenplum open-source version. We hope all open-source developers and users of Greenplum will migrate to Cloudberry.\\n\\n## The Story of Cloudberry\\n\\nBefore going further, we would like to recap the history of the Greenplum Database from closed-source to open-source (October 2015) and then going closed-source (May 2024):\\n\\n- The Greenplum Database has a long history back to 2003 when it was originally developed based on Massively Parallel Processing (MPP) architecture and the PostgreSQL technology by a company called Greenplum Inc.\\n- In 2010, Greenplum Inc. was acquired by EMC Corporation.\\n- In 2012, EMC and VMware (a subsidiary of EMC) combined several of their software assets, including Greenplum Database, into a new company called Pivotal Software, Inc.\\n- In 2015, Pivotal open sourced the Greenplum\u2019s core engine and rebranded it as Pivotal Greenplum Database\xae, which became the first open-source MPP data warehouse. The open-source core of the Pivotal Greenplum Database\xae was used to initiate Apache HAWQ and Apache MADlib projects, while the Greenplum itself remained a single vendor open-source project.\\n- In 2019, VMware acquired Pivotal Software. This acquisition brought the Pivotal Greenplum Database\xae back into VMware. VMware continued to support the Greenplum Database development and its open-source community and provided VMware Tanzu Greenplum as the commercial product in the following years.\\n- In November 2023, Broadcom completed its acquisition of VMware and Greenplum is under Broadcom[^2].\\n- In May 2024, nearly all Greenplum\u2019s GitHub repos were archived and became read-only, the Slack workspace was deleted (https://greenplum.slack.com), and both `user`[^3] and `dev`[^4] community email lists went silent. These are done by its latest owner without any announcements.\\n\\nYou can see that the ownership of Greenplum Database has changed many times over the past many years, which has raised concerns among the community users, developers, and ecosystem partners. Being controlled by one single vendor, Greenplum has lacked an open governance model that allows community participation in the decision-making process.\\n\\nThe Cloudberry builders recognized that the Greenplum Database had lost its drive for innovation and major feature updates for a long time. Greenplum became less competitive compared to newer generation open-source data warehouses and analytics projects.\\n\\nCloudberry was launched in 2022 by the original Greenplum developers, and its source code was made open in 2023. We were surprised when Greenplum suddenly shifted to a closed-source model, which was quite dramatic. From that point on, we were determined to continue our mission and reunite the original open-source Greenplum developers and users, shaping our project in a community way.\\n\\nCloudberry is not only simply remade with a different brand. It comes with a fantastic vision and ships a lot of advanced features and highlights, including a newer PostgreSQL kernel, enhanced security, end-to-end performance optimization, supporting AI/ML workloads and streaming, lakehouse integration, and more. We aim to keep Cloudberry compatible with Greenplum to let users use Cloudberry the way they were using Greenplum.\\n\\n## Why Apache Incubator?\\n\\nJoining the Apache Incubator is a major step for Cloudberry as it opens the door for collaboration, community growth, and innovation within the open-source world. The Apache Incubator provides a framework for the governance, mentoring, and management of open-source projects, ensuring the project\u2019s growth while aligning with the Apache Way\u2014a community-driven development model that emphasizes transparency and open collaboration.\\n\\nAs Cloudberry enters the Incubator, we are more committed than ever to fostering a vibrant, diverse developer community and encouraging contributions from across the globe. Cloudberry will now have the opportunity to benefit from the mentorship of experienced Apache community members. We hope Cloudberry can graduate from ASF Incubator and be mature and successful as a top-level Apache project by following the Apache Way.\\n\\n## Acknowledgments\\n\\nThank you to all contributors from the Cloudberry community and our upstream projects\u2019 contributors for their great contributions! Thanks to Roman Shaposhnik as our Champion, and thanks to Willem Jiang and Kent Yao as our mentors.\\n\\n## Join us\\n\\nAs Cloudberry embarks on this exciting journey within the Apache Incubator, we invite developers, data scientists, and database enthusiasts to get involved in shaping the future of the project. Whether through contributing code, sharing use cases, or participating in discussions, we welcome everyone to join the growing community around Cloudberry.\\n\\nStay tuned for more updates, and join us in building the future of data warehouse and data analytics.\\n\\nYou can find us as follows:\\n\\n- Visit the website: [https://cloudberry.apache.org](https://cloudberry.apache.org)\\n- Follow us on GitHub: [https://github.com/apache/cloudberry](https://github.com/apache/cloudberry)\\n- Join Slack workspace: [https://apache-cloudberry.slack.com](https://apache-cloudberry.slack.com)\\n- Dev mailing list: \\n\\t* To subscribe to dev mailing list: Send an email to dev-subscribe@cloudberry.apache.org\\n\\t* To browse past dev mailing list discussions: https://lists.apache.org/list.html?dev@cloudberry.apache.org\\n\\n[^1]: https://lists.apache.org/thread/qzfb38dzb1x3cg29snq4doy95gd6pzy8\\n[^2]: https://investors.broadcom.com/news-releases/news-release-details/broadcom-completes-acquisition-vmware\\n[^3]: https://groups.google.com/a/greenplum.org/g/gpdb-users\\n[^4]: https://groups.google.com/a/greenplum.org/g/gpdb-dev"}]}')}}]);